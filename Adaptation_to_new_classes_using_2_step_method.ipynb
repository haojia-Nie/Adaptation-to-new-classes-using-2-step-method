{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTGG9Bl_BpAg"
      },
      "source": [
        "# **Adaptation to new classes using 2-step method**\n",
        "\n",
        "Group Member: Chenchen Tang, Haojia Nie\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1QrkwsqeEkB7"
      },
      "source": [
        "This work explores the method using unsupervised to train classification network to detect K+N classes. Given K classes with labels, we use them to train a supervised convolutional neural network. Our goal for this step is to minimize the loss and produce relatively high accuracy for the detection of the K classes. Then we use the trained network and input it with (K+N) classes, which N classes unseen by the network. In this step, we exclude the top dense layers of the trained network and only collect the middle layer features produced by the network. Then we use those features to perform K-means clustering and the classification yield by the clustering would be our prediction result.\n",
        "\n",
        "Besides from that, we've also tried a new way of preprocess the dataset. Instead of using the original image and and apply transformations. We create artificial sample image by randomly choose X images from the same class and combine them together. It helps the network to learn more features and yield a better accuracy for the K+N class detection. \n",
        "\n",
        "The main goal of the project is to produce a way of classification that is able to adapt to new classes. We have demonstrated that using the features of the trained network for clustering performs better than regular K-means using original images. It has been shown that it has the better capability for the classification of unseen classes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S82gipK-Drru"
      },
      "source": [
        "## Team member and contributions\n",
        "\n",
        "Working together\n",
        "\n",
        "*  Search for related resources (paper & tutorial)\n",
        "*  Talk about Central Ideas of project\n",
        "*  Finish Part 3 (Mixing Image and Data Augmentation)\n",
        "*  Finish Part 2a (Creating Network for fully supervised training)\n",
        "*  Test & Debug the whole project\n",
        "*  Talk about the Final Conclusion\n",
        "\n",
        "Chenchen Tang\n",
        "  \n",
        "\n",
        "*   Finish first draft of project (Separate each section in assignment version & Offers some starter code)\n",
        "*   Finish Part 1(a), 1(b) (Initialization and Dataset Preparation / Loading)\n",
        "*   Finish Part 2(b) (Create Own Loss Function, Add Regularization)\n",
        "*   Finish Part 3 (Fully Supervised Train Block & Evaluate Accuracy)\n",
        "*   Finish Part 5(c) (Count clusters and separate them)\n",
        "*   Finish Part 6 ”Manually assign label to cluster” method for evalution\n",
        "*   Finish Part 6(a), 6(b) Generate code to summarize all evaluation\n",
        "\n",
        "Haojia Nie\n",
        "\n",
        "\n",
        "*   Finish Part 1(c) (Create original, diy, combine datasets)\n",
        "*   Finish Part 5(a), 5(b) (Encoder & Decoder of the Unsupervised Section)\n",
        "*   Finish Part 6 (Purity and Rand Index Evalution Methods)\n",
        "*   Polish the code and reorganize the structure (Rewrite code in Classes & Methods format)\n",
        "*   Write the Abstract and Add detailed explaination in the middle section.\n",
        "*   Expand bullet point into Final Conclusion, and add Reference\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WW4P0liXFlRP"
      },
      "source": [
        "## **Part 1: Initialization and Dataset Preparation**\n",
        "In this part, we will do initializations of the whole project who includes the following steps\n",
        "\n",
        "1.   Import the libraries will be used\n",
        "2.   Image Preprocessing and Dataset Loading\n",
        "3.   Mixing Image and Data Augmentation\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTYcA6DAFqCd"
      },
      "source": [
        "#### **a. Import Code Libraries**\n",
        "\n",
        "In this section, we will list out the libraries we use and the importance of using it \n",
        "  * time\n",
        "     * This module provides the time-related functions and we use it to record the time an algorithm or a training takes.\n",
        "  * numpy\n",
        "      * This module provides the array processing functions and we use it for doing array and matrix manupilation.\n",
        "  * matplotlib.pyplot\n",
        "      * This module provides a way to visualize data and we use it to showcase the sample data, learning curve etc.\n",
        "  * pandas\n",
        "      * This module provides the streamlined form of data frame and we used it for doing data analysis and manipulation\n",
        "  * torch\n",
        "      * This module offers a way to create tensor and building network and we used it for building the classification neural network pipeline.\n",
        "  * keras.datasets\n",
        "      * keras.datasets provides a few datasets for machine learning and we used the Fashion MNIST datasets. \n",
        "  * torchvision\n",
        "      * torchvision is a library that provides the computer vision features that can be used with pyTorch, and we use it for image transformation. \n",
        "  * sklearn\n",
        "      * sklearn is a predictive data analysis tools that is compatible with numpy, scipy and matplotlib. We use it to analyse the data including evaluate the performance of clustering and etc.\n",
        "\n",
        "  * itertools\n",
        "      * This implies that the loss function need to be improved for better indication of model accuracy and the network itself may require some redesign."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9PmWJ10uHbFu"
      },
      "outputs": [],
      "source": [
        "# Import python Libraries\n",
        "import time\n",
        "\n",
        "# Import essential libraries for data manipulations.\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import random\n",
        "import itertools\n",
        "\n",
        "# Import libraries for network and k-means\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.transforms.functional as tF\n",
        "from keras.datasets import fashion_mnist\n",
        "from keras import backend\n",
        "from torchvision import datasets, utils, models\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics.cluster import homogeneity_score, normalized_mutual_info_score, adjusted_rand_score\n",
        "from sklearn.model_selection import train_test_split\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63n78AmipBbe"
      },
      "source": [
        "#### **b. Image Preprocessing and Dataset Loading**\n",
        "\n",
        "1. Image Preprocessing \n",
        "\n",
        "    We use several transform function to preprocess the training dataset including Random Crop, Padding, Random Horizontal Flip and Normalization. The reason we add the randomess in the image process (Flip and Crop) is to artificially augment the dataset so that each iteration the network will take a slightly different input. The reason behind cropping is to deal with the potential size difference between each images. Finally, we perform normalization to make the mean and std of each image to be 0 and 1 respectively.\n",
        "\n",
        "2. Choose Dataset \n",
        "\n",
        "    We choose the Fashion MNIST dataset to do classification. The advantages of choosing Fashion MNIST over other dataset is because this dataset better models the real-world computer vision data. And at the same time, it is not as complicated as the real world data which makes it suitable for this group project. \n",
        "\n",
        "3. Data Loading\n",
        "\n",
        "    We load the dataset using torch DataLoader.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rXWJBmRiHg8R"
      },
      "outputs": [],
      "source": [
        "# Define Batch Size \n",
        "batch_size = 64\n",
        "\n",
        "random.seed(0)\n",
        "torch.manual_seed(0)\n",
        "\n",
        "# Define the transformatino for train data\n",
        "train_transform = transforms.Compose([# transforms.ToTensor(),\n",
        "                    # should NOT use RandomResizeCrop too harshly, because this is not a\n",
        "                    # segmentation problem, where each pixel in the output corresponds to the input\n",
        "                    # transforms.RandomCrop(20), # multiple of num_cut\n",
        "                    # transforms.Resize(28, interpolation=transforms.InterpolationMode.NEAREST),\n",
        "                    # transforms.Pad(4),\n",
        "                    transforms.RandomHorizontalFlip(),\n",
        "                    transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "# Define the transformation for test data \n",
        "test_transform = transforms.Compose([transforms.ToTensor()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZQ5cINxwVbcN"
      },
      "outputs": [],
      "source": [
        "# Download and load the training data\n",
        "trainset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/',\n",
        "                  download=True,\n",
        "                  train=True)\n",
        "trainloader = DataLoader(trainset,\n",
        "                      batch_size=batch_size,\n",
        "                      shuffle=True)\n",
        "\n",
        "# Download and load the test data\n",
        "testset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', \n",
        "                  download=True,\n",
        "                  train=False,\n",
        "                  transform=test_transform)\n",
        "testloader = DataLoader(testset,\n",
        "                      batch_size=batch_size,\n",
        "                      shuffle=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kL-3aGyJ79G"
      },
      "source": [
        "#### **c. Mixing Image and Data Augmentation**\n",
        "\n",
        "\n",
        "\n",
        "#####**Methodology**\n",
        "This part is to create our training dataset by combine the original image and mixing normal images which we will explain later.\n",
        "\n",
        "Here we propose a way of creating a single sample image by randomly choose k images from the same class and combine them togher. For example, if we crop it 2 times, one from the center of horizontal line and another from the center of the vertical line. The combined image will be assembled by the cropped pieces of 4 images as shown below.\n",
        "\n",
        "<pre>\n",
        "------------------------\n",
        "            |\n",
        "   img1     |  img2 \n",
        "            |\n",
        "------------------------ \n",
        "            |\n",
        "   img3     |  img4\n",
        "            |\n",
        "------------------------ \n",
        "</pre>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AH8XxuIG5u8A"
      },
      "source": [
        "#####**Implementation Details**\n",
        "\n",
        "First, we implement reconstruct function that randomly choose n images from the same class in dataset. Then it crops each image and combine together and create the mixed image. We named this dataset train_X_diy, train_y_diy. \n",
        "\n",
        "Then, to create the training set, we concatenate the original dataset with the mixed image dataset and get train_X_comb and train_y_comb. This is the preprocess of the dataset.\n",
        "\n",
        "After that, we seperated the dataset(train_X_comb, train_y_comb) into two sets. The first training set has K classes (train_lX_comb, train_ly_comb). We will be using this set for the fully supervised network. Another set has N classes (train_uX_comb, train_uy_comb) and we will be erase their labels. This dataset will be used in the unsupervised classification. \n",
        "\n",
        "\n",
        "Also we create (trainX_flatten) for the comparison test in later section \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tu-imIMiOS0e"
      },
      "outputs": [],
      "source": [
        "# Define K,  N and classes\n",
        "classes = list(trainset.class_to_idx.keys())\n",
        "K = 7\n",
        "N = len(classes) - K"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O-OmapEYPfSp"
      },
      "outputs": [],
      "source": [
        "# Define reconstruct marix\n",
        "\n",
        "def reconstruct(img, target, num_cut, num_dup, num_classes):\n",
        "\n",
        "  # initialize rescontrstuct image, target\n",
        "  reconstruct_img = []\n",
        "  reconstruct_target = []\n",
        "\n",
        "  # Calculate the width and height we need to cut\n",
        "  cut_width = img.size()[1] // num_cut\n",
        "  cut_height = img.size()[2] // num_cut\n",
        "\n",
        "  # define random matrix \n",
        "  rand_matrix = np.random.randint(0, img.size()[0] // num_classes, size=(num_dup,num_cut,num_cut))\n",
        "\n",
        "  # create the reconstrcted image, target\n",
        "  for label in range(num_classes):\n",
        "    img_pool = img[target == label]\n",
        "    for count in range(num_dup):\n",
        "      new_img = np.zeros((img.size()[1], img.size()[2]))\n",
        "\n",
        "      # assign each part with a random image section in the same class\n",
        "      for i in range(num_cut):\n",
        "        for j in range(num_cut):\n",
        "          i1, i2 = i*cut_width, (i+1)*cut_width\n",
        "          j1, j2 = j*cut_height, (j+1)*cut_height\n",
        "          img_idx = rand_matrix[count,i,j]\n",
        "          new_img[i1:i2,j1:j2] = img_pool[img_idx,i1:i2,j1:j2]\n",
        "        \n",
        "      # append the reconstructed image to the list\n",
        "      reconstruct_img.append(list(new_img))\n",
        "      reconstruct_target.append(label)\n",
        "    print(label)\n",
        "  return torch.FloatTensor(reconstruct_img), torch.LongTensor(reconstruct_target)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uwZ3n9apS3Gu",
        "outputId": "4191ae33-ec34-40f5-f195-d089161d7e7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n"
          ]
        }
      ],
      "source": [
        "# Get the training data where X stands for the object and y stands for the target\n",
        "train_X = trainset.data.type(torch.FloatTensor)\n",
        "train_y = trainset.targets\n",
        "\n",
        "test_X = testset.data.type(torch.FloatTensor)\n",
        "test_y = testset.targets\n",
        "\n",
        "# Method 0: Obtain the original data set train_x and train_y\n",
        "train_X_orig = train_X.clone().detach()\n",
        "train_y_orig = train_y.clone().detach()\n",
        "train_X_orig = train_transform(train_X_orig)\n",
        "trainset_orig = TensorDataset(train_X_orig, train_y_orig)\n",
        "trainloader_orig = DataLoader(trainset_orig, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Method 1: Obtain the reconstructed train_x and train_y \n",
        "train_X_diy, train_y_diy = reconstruct(train_X, train_y, num_cut=2, num_dup=6000, num_classes=len(classes))\n",
        "train_X_diy = train_transform(train_X_diy)\n",
        "trainset_diy = TensorDataset(train_X_diy, train_y_diy)\n",
        "trainloader_diy = DataLoader(trainset_diy, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Method 2: Obtain the combined data set of the original and reconstructed\n",
        "train_X_comb = torch.cat((train_X_orig, train_X_diy))\n",
        "train_y_comb = torch.cat((train_y_orig, train_y_diy))\n",
        "trainset_comb = torch.utils.data.ConcatDataset([trainset_orig, trainset_diy])\n",
        "trainloader_comb = DataLoader(trainset_comb, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vfC6iFDJeJ9J",
        "outputId": "9285b67a-b9d8-4690-c19e-b90c0b28e8fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([60000, 28, 28])\n",
            "torch.Size([60000, 28, 28])\n",
            "torch.Size([120000, 28, 28])\n"
          ]
        }
      ],
      "source": [
        "print(train_X_orig.size())\n",
        "print(train_X_diy.size())\n",
        "print(train_X_comb.size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5irANDHa72s",
        "outputId": "4ca9b9ef-5228-46fd-b29b-6346f94575b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "random chosen index:  [3, 5, 4, 7, 0, 2, 1]\n"
          ]
        }
      ],
      "source": [
        "# To Filter the K classes we want from the dataset x\n",
        "K = 7\n",
        "arr = random.sample(range(0, 10), K)\n",
        "arr = [3,5,4,7,0,2,1]\n",
        "print(\"random chosen index: \", arr)\n",
        "def filter_K_class(x, chosen = arr):\n",
        "  if x in arr:\n",
        "    return True\n",
        "  return False\n",
        "\n",
        "# Obtain the filtered K Classes\n",
        "def label_train_set(data_X, label_Y):\n",
        "  train_x = data_X.clone().detach()\n",
        "  train_y = label_Y.clone().detach()\n",
        "  idx = np.array([filter_K_class(y) for y in train_y])\n",
        "  train_x = train_x[idx].type(torch.FloatTensor)\n",
        "  train_y = train_y[idx]\n",
        "  trainset = TensorDataset(train_x, train_y)\n",
        "  trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
        "  return trainset, trainloader, train_x, train_y\n",
        "\n",
        "# Obtain the unlabled N classes\n",
        "def unlabel_train_set(data_X, label_Y):\n",
        "  train_X = data_X.clone().detach()\n",
        "  train_y = label_Y.clone().detach()\n",
        "  idx = np.array([filter_K_class(y) for y in train_y])\n",
        "  train_X = train_X[~idx].type(torch.FloatTensor)\n",
        "  train_y = train_y[~idx]\n",
        "  trainset = TensorDataset(train_X, train_y)\n",
        "  trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
        "  return trainset, trainloader, train_X, train_y\n",
        "\n",
        "# labeled training set\n",
        "trainset_l_orig, trainloader_l_orig, train_lX_orig, train_ly_orig = label_train_set(train_X_orig, train_y_orig)\n",
        "trainset_l_diy, trainloader_l_diy, train_lX_diy, train_ly_diy = label_train_set(train_X_diy, train_y_diy)\n",
        "trainset_l_comb, trainloader_l_comb, train_lX_comb, train_ly_comb = label_train_set(train_X_comb, train_y_comb)\n",
        "\n",
        "# unlabled training_set\n",
        "trainset_ul_orig, trainloader_ul_orig, train_uX_orig, train_uy_orig = unlabel_train_set(train_X_orig, train_y_orig)\n",
        "trainset_ul_diy, trainloader_ul_diy, train_uX_diy, train_uy_diy = unlabel_train_set(train_X_diy, train_y_diy)\n",
        "trainset_ul_comb, trainloader_ul_comb, train_uX_comb, train_uy_comb = unlabel_train_set(train_X_comb, train_y_comb)\n",
        "\n",
        "testset_l, testloader_l, testset_lX, testset_ly = label_train_set(test_X, test_y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kC4bulsrdLrW",
        "outputId": "8541f0c1-27a9-494e-9b46-c7a0753e7027"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 28, 28]) torch.FloatTensor torch.LongTensor\n",
            "torch.Size([64, 28, 28]) torch.FloatTensor torch.LongTensor\n",
            "torch.Size([60000, 784]) torch.FloatTensor\n",
            "torch.Size([42000, 784]) torch.FloatTensor\n",
            "torch.Size([18000, 784]) torch.FloatTensor\n"
          ]
        }
      ],
      "source": [
        "# Here print the size, type, label type for trainLoader_original\n",
        "for images, labels in trainloader_orig:\n",
        "  print(images.size(), images.type(), labels.type())\n",
        "  break\n",
        "\n",
        "for images, labels in trainloader_l_orig:\n",
        "  print(images.size(), images.type(), labels.type())\n",
        "  break\n",
        "\n",
        "\n",
        "# original total dataset size\n",
        "trainX_flatten = torch.flatten(train_X_orig, 1).type(torch.FloatTensor)\n",
        "print(trainX_flatten.shape, trainX_flatten.type())\n",
        "\n",
        "# the labeled K dataset size\n",
        "trainlX_flatten = torch.flatten(train_lX_orig, 1).type(torch.FloatTensor)\n",
        "print(trainlX_flatten.shape, trainlX_flatten.type())\n",
        "\n",
        "# the unlabeled N dataset size\n",
        "trainX2_flatten = torch.flatten(train_uX_orig, 1).type(torch.FloatTensor)\n",
        "print(trainX2_flatten.shape, trainX2_flatten.type())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zs4gjdtRJmwC"
      },
      "source": [
        "(b). The following cell shows some sample image in dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "id": "pNTVd013KV6Z",
        "outputId": "134e8f1f-fe2e-4e61-b179-49b269db2a04"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 9 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Display the sample images we have preprocessed\n",
        "def show_sample_img(trainset):\n",
        "\tfigure = plt.figure(figsize=(8, 8))\n",
        "\tcols, rows = 3, 3\n",
        "\tfor i in range(1, cols * rows + 1):\n",
        "\t\tsample_idx = torch.randint(len(trainset), size=(1,)).item()\n",
        "\t\timg, label = trainset[sample_idx]\n",
        "\t\tfigure.add_subplot(rows, cols, i)\n",
        "\t\tplt.title(classes[label])\n",
        "\t\tplt.axis(\"off\")\n",
        "\t\tplt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "\tplt.show()\n",
        "\n",
        "show_sample_img(trainset_diy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yzautidKWdK"
      },
      "source": [
        "## **Part 2: Implement network for fully supervised training**\n",
        "In this part, we implemented the first step of the two-step method which is a supervised network (TRAINED_NET). We train the network by inputting images from K classes.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7gX3o8Ck0SL"
      },
      "source": [
        "### **(a). Build the Network**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "068kFhKyNCfZ"
      },
      "outputs": [],
      "source": [
        "# Define the Network \n",
        "class Net(nn.Module):\n",
        "  def __init__(self, num_classes=len(classes), criterion=None):\n",
        "    super(Net, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
        "    self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
        "    self.conv3 = nn.Conv2d(64, 4, 3, 1)\n",
        "    self.dropout = nn.Dropout(0.2)\n",
        "    self.fc1 = nn.Linear(1936, 128)\n",
        "    self.fc2 = nn.Linear(128, num_classes)\n",
        "\n",
        "  def forward(self, x, include_top=True):\n",
        "    x = self.conv1(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.conv2(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.conv3(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.dropout(x)\n",
        "    if include_top:\n",
        "      x = torch.flatten(x, 1)\n",
        "      x = self.fc1(x)\n",
        "      x = F.relu(x)\n",
        "      x = self.dropout(x)\n",
        "      x = self.fc2(x)\n",
        "    else:\n",
        "      x = torch.flatten(x, 1)\n",
        "    return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RB730x9slRic"
      },
      "source": [
        "### **(b). Define Loss Function**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kNO-eRKflU6t"
      },
      "outputs": [],
      "source": [
        "class MyCrossEntropyLoss(nn.Module):\n",
        "\n",
        "  use_custom = False\n",
        "\n",
        "  def __init__(self, params, lam):\n",
        "    super(MyCrossEntropyLoss, self).__init__()\n",
        "    self.params = params\n",
        "    self.lam = lam\n",
        "\n",
        "  def softmax(self, logits):\n",
        "    if self.use_custom:\n",
        "      exp_x = torch.exp(logits - torch.max(logits, 1, keepdim=True)[0])\n",
        "      exp_x_sum = torch.sum(exp_x, 1, keepdim=True)\n",
        "      x = torch.log(exp_x / exp_x_sum)\n",
        "    else:\n",
        "      x = F.log_softmax(logits, -1)\n",
        "    return x\n",
        "\n",
        "  def to_onehot(self, targets, num_classes):\n",
        "    if self.use_custom:\n",
        "      ones = torch.sparse.torch.eye(num_classes)\n",
        "      y = ones.index_select(0, targets.cpu()).to(device)\n",
        "    else:\n",
        "      y = F.one_hot(targets, num_classes=num_classes)\n",
        "    return y\n",
        " \n",
        "  def forward(self, logits, targets):\n",
        "    x = self.softmax(logits)\n",
        "    y = self.to_onehot(targets, logits.size()[1])\n",
        "    loss = - torch.sum(x * y) / logits.size()[0]\n",
        "    reg = 0\n",
        "    for p in self.params:\n",
        "      reg += p.abs().sum()\n",
        "    loss += self.lam * reg\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vG8wkO8gNPVI"
      },
      "source": [
        "## **Part 3: Fully supervised training**\n",
        "In this part, we will build the network (TRAINED_NET) and trained to classify K classes. Our idea is that we use the images from the K classes for training the network and tunning its parameters. If the network has lower loss value that means it has better capability of differentiating the K classe. Then, in the later K-means classification, the features we use will better differentiate those K class from the N classes and may produce more accurate classification."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note**\n",
        "\n",
        "In our network, we add in an important parameter called include_top. This parameter seperates the fully connected layers and the layers before it. If we set the include_top to be True, we will obtain the features created by the nerual network instead of the final classification label. For now, we set the default value of include_top to be True, later we will set it to False for the use of unsupervised classification. \n",
        "\n"
      ],
      "metadata": {
        "id": "WJooNmjtDCtm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SfQZxZn0xpNs"
      },
      "outputs": [],
      "source": [
        "# Define use of GPU or CPU\n",
        "USE_GPU = True\n",
        "device = 'cpu'\n",
        "if USE_GPU:\n",
        "  device = 'cuda'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZjKK14aaIns2"
      },
      "outputs": [],
      "source": [
        "# We use Cross Entropy Loss as loss function and Adam as Optimizer\n",
        "model = Net().to(device)\n",
        "criterion = MyCrossEntropyLoss(model.parameters(), 0.1)\n",
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "untrained_model = Net().to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BqXsfh15x0Io"
      },
      "source": [
        "**Epoch**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tGt4DD6rN1lH",
        "outputId": "ff5ab51e-c310-408e-d58a-6896a7f90d48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  0, Train Loss:  2.29, Test Loss:  1.95\n",
            "Epoch:  1, Train Loss:  1.95, Test Loss:  1.95\n",
            "Epoch:  2, Train Loss:  1.95, Test Loss:  1.95\n",
            "Epoch:  3, Train Loss:  1.95, Test Loss:  1.95\n",
            "Epoch:  4, Train Loss:  1.95, Test Loss:  1.95\n",
            "Epoch:  5, Train Loss:  1.95, Test Loss:  1.95\n",
            "Epoch:  6, Train Loss:  1.95, Test Loss:  1.95\n",
            "Epoch:  7, Train Loss:  1.95, Test Loss:  1.95\n",
            "Epoch:  8, Train Loss:  1.95, Test Loss:  1.95\n",
            "Epoch:  9, Train Loss:  1.95, Test Loss:  1.95\n"
          ]
        }
      ],
      "source": [
        "epoch = 10\n",
        "\n",
        "def get_loss(model, trainloader, testloader, epoch):\n",
        "  index = 0\n",
        "  train_loss = []\n",
        "  test_loss = []\n",
        "  test_accu = []\n",
        "  while index < epoch:\n",
        "    run_loss = 0\n",
        "    model.train()\n",
        "    for images, labels in trainloader:\n",
        "\n",
        "      images, labels = images.to(device), labels.to(device)\n",
        "      optimizer.zero_grad()\n",
        "      output = model(images[:,None,:,:])\n",
        "      loss = criterion(output, labels)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      run_loss += loss.item()\n",
        "\n",
        "    training_loss = run_loss/len(trainloader)\n",
        "    train_loss.append(training_loss)\n",
        "    print(\"Epoch: {:2}, Train Loss:  {:1.3}\".format(index, training_loss),end=\", \")\n",
        "\n",
        "    run_loss = 0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      for images, labels in testloader:\n",
        "          \n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        output = model(images[:,None,:,:])\n",
        "        loss = criterion(output, labels)\n",
        "\n",
        "        run_loss += loss.item()\n",
        "\n",
        "    testing_loss = run_loss/len(testloader)\n",
        "    test_loss.append(testing_loss)\n",
        "    print(\"Test Loss:  {:1.3}\".format(testing_loss))\n",
        "    index += 1\n",
        "\n",
        "  return train_loss, test_loss\n",
        "\n",
        "# use the labeled (seen) classes in trainset\n",
        "train_loss, test_loss = get_loss(model, trainloader_l_comb, testloader_l, epoch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hbj5SRUF7iNy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "2be832bd-7e79-4c7a-b967-f2fce6c7745d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqwAAAGBCAYAAACjGONFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzde5icZZ3n//e3unM+VRMikKSa4BFCgG6MCIOMog4COuI4v8ETOh7xN+Ps4K4yIuvK6MxvBi9dRl1FBgTdUTwtyKwzMAruyAirIiGJBAhyEnMCCYF0DuTY/f39UU8nlU53upN0dVW636/r6quqnud+7vpWddF8ctf9PHdkJpIkSVKzKjW6AEmSJGlfDKySJElqagZWSZIkNTUDqyRJkpqagVWSJElNzcAqSZKkpmZglbTfIuLxiHhto+topIj4o4hYGRGbIqKz0fXsS0T8dUR8c4htb4+I99e7pkaKiK9HxN82ug5JQ2dglaQD8zngLzJzamYuaXQxkjSaGVgljQkR0TrMXR4N3H+AtbQMcy2SNKoZWCUdlIiYEBGfj4g1xc/nI2JCse/wiPjXiFgfEc9ExB0RUSr2fSwiVkfExoj4dUS8ZoD+J0XEf4+I30ZEV0TcWWx7VUSs6tN211SF4mvwGyLimxGxAbg0IrZExGE17Tsj4umIGFc8fm9ELI+IZyPiRxFx9ACvdxPQAvwqIh4tth9XfJ2+PiLuj4g31hzz9Yj4SkTcEhGbgTP76ff2iPjbiPhZMc3gXyJiZkRcHxEbIuLuiJhX0/73im1dxe3v1ew7JiL+o3hvbwMO7/NcpxbPsz4ifhURr+r/t7vHMbP39f5FxAuL5+wqtn13sD5r+hnwfY+IjIi/jIjHin4/W/MZKkXEJ4rPxlMR8U8RMaPm2FfUvM6VEfHumqdti4ibi/foroh4QXFMRMQ/FP1tiIhlEbFgqK9FUn0YWCUdrP8KnAp0ACcBpwCfKPZ9BFgFzAKOAC4FMiJeAvwF8LLMnAa8Dnh8gP4/B7wU+D3gMOCvgJ4h1nYecANQBj4L/Bz445r9bwduyMwdEXFeUd+bi3rvAL7dt8PM3JaZU4uHJ2XmC4rA+y/ArcDzgP8EXF+8ztrn+v+AacCdA9T7VuCdwBzgBUW9Xyte93LgMoAiNN4MfBGYCVwB3BwRM4t+vgXcQzWo/g3wp71PEBFzimP/tuj3o8CNETFrgJp6X/ca9vH+Fc9zK9AGzAX+x776q6lnKO/7HwELgZOp/k7fW2x/d/FzJvB8YCrwpaLfo4F/K+qYRfXzubSmz7cCnyrqfYTq7wbgLOD3gRcDM4DzgXVDeS2S6sfAKulgvQP4dGY+lZlrqYaAdxb7dgBHAUdn5o7MvCMzE+gGJgDzI2JcZj6emY/27bgYSXsvcFFmrs7M7sz8WWZuG2JtP8/Mf87MnszcQjXIva3oO6iGlm8Vbf9f4O8zc3lm7gT+Dujob5S1H6dSDUuXZ+b2zPx34F97n6vwvzPz/xa1bB2gn69l5qOZ2UU1bD2amT8u6vlfQO/JXa8HHs7Mb2Tmzsz8NvAg8IcR0Q68DPhvRbj+KdUw3esC4JbMvKWo5TZgEXDuEF7nvt6/HVSnSczOzK2ZOVAo72so7/tnMvOZzFwBfJ7d7+s7gCsy87HM3AR8HHhrVKd/vB34cWZ+u/jsrcvM2sB6U2b+snjO66kG2t7XMQ04FoiirieG+Fok1YmBVdLBmg38tubxb4ttUB3VfAS4tfhK9xKAzHwE+DDw18BTEfGdiJjN3g4HJgJ7hdkhWtnn8Y3AaRFxFNVRtB6qI3pQDVtfKL4+Xg88AwTV0c7BzAZWZmbtyO9v+xzbt5b+/K7m/pZ+HveO7PZ9z2ufbzbwbGZu7rOv19HAn/S+zuK1voLqPywGs6/376+ovl+/LKZEvHeAPvoayvte+97Vfr76++y1Uh3Nr7Dvz82TNfefo3hvi39sfAn4MtXP5tURMX2Ir0VSnRhYJR2sNVRDR6/2YhuZuTEzP5KZzwfeCPyXKOaqZua3MvMVxbEJfKafvp8GtlL9eryvzcDk3gdRPZGp79fauceDzGepfm39FqojcN8pRnyhGoo+mJnlmp9JmfmzQd+B6uut9M6tLLQDqweq5SD1fc9rn+8JqvMzp/TZ12sl8I0+r3NKZl4+2JPu6/3LzCcz8wOZORv4IHBlRLxwCK9lKO97pc9rWVPc7++zt5Nq0F9J/5+bQWXmFzPzpcB8qlMDLj6QfiQNHwOrpIP1beATETErIg4HPgl8EyAi3lCcjBNAF9WpAD0R8ZKIeHVUT87aSnX0cK95qcWI5XXAFcVJPy0RcVpx3EPAxIh4fTGH9BNUpxkM5lvAu4D/h91fZwNcBXw8Io4vap8REX8yxPfgLqqjdH9VnID0KuAPge8M8fj9dQvw4oh4e0S0RsRbqIarf83M31L9iv9TETE+Il5R1NLrm1SnDryueD8nRvUEtrlDfO5+37+I+JOaPp6lGtCHMtd4KO/7xRHRFhEV4CKg94SubwP/OaonmU2lOp3guzVf8782Is4v3qOZEdHBICLiZRHx8uIztZnq53Ooc6Yl1YmBVdLB+luqAeleYBmwuNgG8CLgx8AmqifsXJmZP6EaLC+nOoL6JNUTlT4+QP8fLfq9m+rXxZ8BSsU8zz8Hvkp1ZHEz1RO8BvODoq4nM/NXvRsz86ai7+9E9aoC9wHnDKE/MnM71VB4TvGargTelZkPDuX4/ZWZ64A3UD2pbR3Vr+PfkJlPF03eDryc6vt1GfBPNceupHri0qXAWqojkRcz9P8f9Pv+UZ03e1dUr6DwA6rzjh8DKKYIvGOA1zKU9/1/Uz2JbCnVE8auLbZfB3wD+CnwG6rh8j8V/a6gOi/3I8X7sJTqSYGDmQ5cQzV0/5bq+/vZIRwnqY5i97dhkiQ1l4hI4EXFvGdJY5QjrJIkSWpqBlZJkiQ1NacESJIkqak5wipJkqSmZmCVJElSU2utV8fF9fL+ieqKIwlcnZlf6NPmPKrrT/dQvdjzh3uX84uIP2X3euR/m5n/c7DnPPzww3PevHnD9hokSZI0Mu65556nM7PvAjBAHeewFkv3HZWZiyNiGtVr6L0pMx+oaTMV2JyZGREnAt/LzGMj4jCq13VcSDXs3gO8tFhlZUALFy7MRYsW1eX1SJIkqX4i4p7MXNjfvrpNCcjMJzJzcXF/I7CcPmtyZ+ammmURp7B76cLXAbdl5jNFSL0NOLtetUqSJKl5jcgc1oiYB3RSXb6w774/iogHqa5e8t5i8xyqq6/0WkWfsFtz/IURsSgiFq1du3Y4y5YkSVITqHtgLb72v5Hq/NQNffdn5k2ZeSzwJqrzWfdLZl6dmQszc+GsWf1Oe5AkSdIhrG4nXQFExDiqYfX6zPz+vtpm5k8j4vkRcTjVdcFfVbN7LnB7veqUJEljw44dO1i1ahVbt25tdClj1sSJE5k7dy7jxo0b8jH1vEpAANcCyzPzigHavBB4tDjp6mRgArAO+BHwdxHRVjQ9C/h4vWqVJEljw6pVq5g2bRrz5s2jGlU0kjKTdevWsWrVKo455pghH1fPEdbTgXcCyyJiabHtUqAdIDOvAv4YeFdE7AC2AG8pTsJ6JiL+Bri7OO7TmflMHWuVJEljwNatWw2rDRQRzJw5k/0976hugbW4nuo+Pw2Z+RngMwPsuw64rg6lSZKkMcyw2lgH8v670pUkSdIIWb9+PVdeeeUBHXvuueeyfv36fbb55Cc/yY9//OMD6r+vefPm8fTTTw9LXwfLwCpJkjRC9hVYd+7cuc9jb7nlFsrl8j7bfPrTn+a1r33tAdfXrAyskiRJI+SSSy7h0UcfpaOjg4svvpjbb7+dM844gze+8Y3Mnz8fgDe96U289KUv5fjjj+fqq6/edWzviOfjjz/Occcdxwc+8AGOP/54zjrrLLZs2QLAu9/9bm644YZd7S+77DJOPvlkTjjhBB588EEA1q5dyx/8wR9w/PHH8/73v5+jjz560JHUK664ggULFrBgwQI+//nPA7B582Ze//rXc9JJJ7FgwQK++93v7nqN8+fP58QTT+SjH/3osLxvdb2slSRJUrP61L/czwNr9rpE/EGZP3s6l/3h8QPuv/zyy7nvvvtYurR6Pvrtt9/O4sWLue+++3adNX/ddddx2GGHsWXLFl72spfxx3/8x8ycOXOPfh5++GG+/e1vc80113D++edz4403csEFF+z1fIcffjiLFy/myiuv5HOf+xxf/epX+dSnPsWrX/1qPv7xj/PDH/6Qa6+9dp+v6Z577uFrX/sad911F5nJy1/+cl75ylfy2GOPMXv2bG6++WYAurq6WLduHTfddBMPPvggETHoFIahcoT1AK1ev4Vlq7oaXYYkSTrEnXLKKXtc4umLX/wiJ510EqeeeiorV67k4Ycf3uuYY445ho6ODgBe+tKX8vjjj/fb95vf/Oa92tx555289a1vBeDss8+mra2t32N73XnnnfzRH/0RU6ZMYerUqbz5zW/mjjvu4IQTTuC2227jYx/7GHfccQczZsxgxowZTJw4kfe97318//vfZ/Lkyfv7dvTLEdYDdMmN97Ju03ZuueiMRpciSZIOwL5GQkfSlClTdt2//fbb+fGPf8zPf/5zJk+ezKte9ap+FzmYMGHCrvstLS27pgQM1K6lpWXQObL768UvfjGLFy/mlltu4ROf+ASvec1r+OQnP8kvf/lL/s//+T/ccMMNfOlLX+Lf//3fD/q5HGE9QB2VMr/+3Uae2z68v3xJkjR6TZs2jY0bNw64v6uri7a2NiZPnsyDDz7IL37xi2Gv4fTTT+d73/seALfeeivPPvvsPtufccYZ/PM//zPPPfccmzdv5qabbuKMM85gzZo1TJ48mQsuuICLL76YxYsXs2nTJrq6ujj33HP5h3/4B371q18NS82OsB6gzvYy3T3JslVdvPz5Mwc/QJIkjXkzZ87k9NNPZ8GCBZxzzjm8/vWv32P/2WefzVVXXcVxxx3HS17yEk499dRhr+Gyyy7jbW97G9/4xjc47bTTOPLII5k2bdqA7U8++WTe/e53c8oppwDw/ve/n87OTn70ox9x8cUXUyqVGDduHF/5ylfYuHEj5513Hlu3biUzueKKfhc73W9RXVhqdFi4cGEuWrRoRJ5r3aZtvPRvf8zHzzmWD77yBSPynJIk6eAsX76c4447rtFlNNS2bdtoaWmhtbWVn//85/zZn/3ZrpPARkp/v4eIuCczF/bX3hHWAzRz6gTaD5vMkhXDc/abJEnSSFixYgXnn38+PT09jB8/nmuuuabRJQ3KwHoQOtvL3PXYM40uQ5Ikache9KIXsWTJkkaXsV886eogdFTKPLlhK0909X9mniRJkg6egfUgdLZXr1u21GkBkiRJdWNgPQjHHTWN8S0llq40sEqSJNWLgfUgTGht4fg50z3xSpIkqY4MrAepo1Lm3tXr2dnd0+hSJElSk1u/fj1XXnnlAR//+c9/nueee27X43PPPZf16w9+4Ozxxx9nwYIFB91PvRhYD1Jnextbd/Tw4JMDr1ohSZIEwx9Yb7nlFsrl8nCU1tQMrAeps1L9kDiPVZIkDeaSSy7h0UcfpaOjg4svvhiAz372s7zsZS/jxBNP5LLLLgNg8+bNvP71r+ekk05iwYIFfPe73+WLX/wia9as4cwzz+TMM88EYN68eTz99NM8/vjjHHfccXzgAx/g+OOP56yzzmLLlupVjO6++25OPPHEXc852Ejq1q1bec973sMJJ5xAZ2cnP/nJTwC4//77OeWUU+jo6ODEE0/k4Ycf7rfOevA6rAdpbtskDp86niUr1nPBqUc3uhxJkjRU/3YJPLlsePs88gQ45/IBd19++eXcd999u1aWuvXWW3n44Yf55S9/SWbyxje+kZ/+9KesXbuW2bNnc/PNNwPQ1dXFjBkzuOKKK/jJT37C4YcfvlffDz/8MN/+9re55pprOP/887nxxhu54IILeM973sM111zDaaedxiWXXDLoS/jyl79MRLBs2TIefPBBzjrrLB566CGuuuoqLrroIt7xjnewfft2uru7ueWWW/aqsx4cYT1IEUFHpczSlc82uhRJknSIufXWW7n11lvp7Ozk5JNP5sEHH+Thhx/mhBNO4LbbbuNjH/sYd9xxBzNmzBi0r2OOOYaOjg4AXvrSl/L444+zfv16Nm7cyGmnnQbA29/+9kH7ufPOO7ngggsAOPbYYzn66KN56KGHOO200/i7v/s7PvOZz/Db3/6WSZMmHVCdB8IR1mHQ2d7Gj5c/RddzO5gxeVyjy5EkSUOxj5HQkZKZfPzjH+eDH/zgXvsWL17MLbfcwic+8Qle85rX8MlPfnKffU2YMGHX/ZaWll1TAobL29/+dl7+8pdz8803c+655/KP//iPvPrVr97vOg+EI6zDoKOYx/qrVc5jlSRJA5s2bRobN+4+Uft1r3sd1113HZs2bQJg9erVPPXUU6xZs4bJkydzwQUXcPHFF7N48eJ+jx9MuVxm2rRp3HXXXQB85zvfGfSYM844g+uvvx6Ahx56iBUrVvCSl7yExx57jOc///n85V/+Jeeddx733nvvgHUON0dYh8GJc2cQAUtWrOf3Xzyr0eVIkqQmNXPmTE4//XQWLFjAOeecw2c/+1mWL1++6yv7qVOn8s1vfpNHHnmEiy++mFKpxLhx4/jKV74CwIUXXsjZZ5/N7Nmzd50MNZhrr72WD3zgA5RKJV75ylcO+rX9n//5n/Nnf/ZnnHDCCbS2tvL1r3+dCRMm8L3vfY9vfOMbjBs3jiOPPJJLL72Uu+++u986h1tkZl06boSFCxfmokWLGvLcZ/3DfzCnPImvveeUhjy/JEka3PLlyznuuOMaXcaI2rRpE1OnTgWqJ3098cQTfOELX2hoTf39HiLinsxc2F97R1iHSWeljVsfeJLMJCIaXY4kSRIAN998M3//93/Pzp07Ofroo/n617/e6JL2m4F1mHS0l/nuopX8dt1zzDt8SqPLkSRJAuAtb3kLb3nLWxpdxkHxpKth0tlePfFqiZe3kiRJGlYG1mHyoudNY8r4Fpau8EoBkiQ1s9F0/s6h6EDefwPrMGkpBSfOLbPEJVolSWpaEydOZN26dYbWBslM1q1bx8SJE/frOOewDqOO9jLX/PQxtu7oZuK4lkaXI0mS+pg7dy6rVq1i7dq1jS5lzJo4cSJz587dr2MMrMOos1JmZ09y/5ouXnr0YY0uR5Ik9TFu3DiOOeaYRpeh/eSUgGHU0XvilfNYJUmSho2BdRg9b9pE5pQnOY9VkiRpGBlYh1lHe9krBUiSJA2jugXWiKhExE8i4oGIuD8iLuqnzTsi4t6IWBYRP4uIk2r2PV5sXxoRjVlv9QB0VsqsXr+FpzZubXQpkiRJo0I9R1h3Ah/JzPnAqcCHImJ+nza/AV6ZmScAfwNc3Wf/mZnZMdC6ss2odwEBR1klSZKGR90Ca2Y+kZmLi/sbgeXAnD5tfpaZvUtD/QLYv2scNKHjZ8+gtRQsdR6rJEnSsBiROawRMQ/oBO7aR7P3Af9W8ziBWyPinoi4sH7VDa+J41qYP3u6VwqQJEkaJnW/DmtETAVuBD6cmRsGaHMm1cD6iprNr8jM1RHxPOC2iHgwM3/az7EXAhcCtLe3D3v9B6KjUubGe1bR3ZO0lKLR5UiSJB3S6jrCGhHjqIbV6zPz+wO0ORH4KnBeZq7r3Z6Zq4vbp4CbgFP6Oz4zr87MhZm5cNasWcP9Eg5IZ3uZzdu7efipjY0uRZIk6ZBXz6sEBHAtsDwzrxigTTvwfeCdmflQzfYpETGt9z5wFnBfvWodbh2VNsATryRJkoZDPacEnA68E1gWEUuLbZcC7QCZeRXwSWAmcGU137KzuCLAEcBNxbZW4FuZ+cM61jqs5s2cTHnyOJasWM9bT2mOaQqSJEmHqroF1sy8E9jnBM7MfD/w/n62PwactPcRh4aIoKNS9koBkiRJw8CVruqks9LGQ09tZOPWHY0uRZIk6ZBmYK2TjvYymbBsVVejS5EkSTqkGVjrpGNudcWrJU4LkCRJOigG1jqZMXkcz581xQUEJEmSDpKBtY46K20sXfksmdnoUiRJkg5ZBtY66mgv8/Sm7ax6dkujS5EkSTpkGVjrqLPiPFZJkqSDZWCto2OPnMbEcSVXvJIkSToIBtY6am0pceKcMktWPtvoUiRJkg5ZBtY662gvc/+aDWzb2d3oUiRJkg5JBtY666iU2b6zh+VPbGx0KZIkSYckA2uddbZXT7xausJpAZIkSQfCwFpnR82YxBHTJ3ilAEmSpANkYB0B1QUEDKySJEkHwsA6Ajray/x23XOs27St0aVIkiQdcgysI6B3AYFfrXKUVZIkaX8ZWEfACXNn0FIKFxCQJEk6AAbWETB5fCsvOWKaJ15JkiQdAAPrCOloL7N05Xp6erLRpUiSJB1SDKwjpLNSZuPWnTz29KZGlyJJknRIMbCOkN4FBJY4j1WSJGm/GFhHyPMPn8q0ia3OY5UkSdpPBtYRUioFHZWyVwqQJEnaTwbWEdRZKfPgkxt4bvvORpciSZJ0yDCwjqCO9jI9CctWdTW6FEmSpEOGgXUEdVTaAJzHKkmStB8MrCPosCnjOXrmZOexSpIk7QcD6wjrrJRZsvLZRpchSZJ0yDCwjrCOSpnfbdjGE11bGl2KJEnSIcHAOsI624t5rE4LkCRJGhID6wg77qjpjG8tsdQTryRJkobEwDrCxreWWDB7OktWOI9VkiRpKAysDdBRaWPZ6i52dPc0uhRJkqSmZ2BtgI72Mlt39PDrJzc2uhRJkqSmV7fAGhGViPhJRDwQEfdHxEX9tHlHRNwbEcsi4mcRcVLNvrMj4tcR8UhEXFKvOhuhs1IGXEBAkiRpKOo5wroT+EhmzgdOBT4UEfP7tPkN8MrMPAH4G+BqgIhoAb4MnAPMB97Wz7GHrLltkzh86njnsUqSJA1B3QJrZj6RmYuL+xuB5cCcPm1+lpm9qe0XwNzi/inAI5n5WGZuB74DnFevWkdaRNBRafNKAZIkSUMwInNYI2Ie0AnctY9m7wP+rbg/B1hZs28VfcLuoa6zvcxjazfT9dyORpciSZLU1OoeWCNiKnAj8OHM3DBAmzOpBtaPHUD/F0bEoohYtHbt2oMrdgT1zmNduspRVkmSpH2pa2CNiHFUw+r1mfn9AdqcCHwVOC8z1xWbVwOVmmZzi217ycyrM3NhZi6cNWvW8BVfZyfMnUEELHXFK0mSpH2q51UCArgWWJ6ZVwzQph34PvDOzHyoZtfdwIsi4piIGA+8FfhBvWpthGkTx/Hi501jyUpPvJIkSdqX1jr2fTrwTmBZRCwttl0KtANk5lXAJ4GZwJXVfMvOYrR0Z0T8BfAjoAW4LjPvr2OtDdFRKfOjB54kMylevyRJkvqoW2DNzDuBfaawzHw/8P4B9t0C3FKH0ppGZ3uZ7y5ayePrnuOYw6c0uhxJkqSm5EpXDdTRXpx45bQASZKkARlYG+hFz5vGlPEtLPHEK0mSpAEZWBuopRScOLfsAgKSJEn7YGBtsM72Mg+s2cDWHd2NLkWSJKkpGVgbrKNSZmdPcv+arkaXIkmS1JQMrA3We+KV81glSZL6Z2BtsOdNm8ic8iSWOI9VkiSpXwbWJtDZXnaJVkmSpAEYWJtAR6XM6vVbeGrD1kaXIkmS1HQMrE2gs70NwGkBkiRJ/TCwNoHjZ09nXEt4PVZJkqR+GFibwMRxLcw/ajpLVrhEqyRJUl8G1ibRUSlz76ouunuy0aVIkiQ1FQNrk+hoL/Pc9m4e+t3GRpciSZLUVAysTaKzUj3xynmskiRJezKwNomjZ06mbfI457FKkiT1YWBtEhFBR6XsCKskSVIfBtYm0lFp4+GnNrFx645GlyJJktQ0DKxNpLO9TCbcu6qr0aVIkiQ1DQNrEzmpUgZwHqskSVINA2sTmTFpHC+YNcV5rJIkSTUMrE2mo9LG0pXryXQBAUmSJDCwNp3O9jJPb9rOqme3NLoUSZKkpmBgbTIdvfNYnRYgSZIEGFibzrFHTmPiuJInXkmSJBUMrE2mtaXEiXNcQECSJKmXgbUJdbaXuX/1Brbt7G50KZIkSQ1nYG1CHZUy27t7WP7ExkaXIkmS1HAG1ibU2d4GuICAJEkSGFib0pEzJnLk9InOY5UkScLA2rQ628ssWWFglSRJMrA2qY5KmRXPPMe6TdsaXYokSVJDGVibVO88VqcFSJKksc7A2qROmDODllIYWCVJ0phXt8AaEZWI+ElEPBAR90fERf20OTYifh4R2yLio332PR4RyyJiaUQsqledzWrS+BZecsQ057FKkqQxr7WOfe8EPpKZiyNiGnBPRNyWmQ/UtHkG+EvgTQP0cWZmPl3HGptaZ3uZHyxdQ09PUipFo8uRJElqiLqNsGbmE5m5uLi/EVgOzOnT5qnMvBvYUa86DmUdlTIbt+3k0bWbGl2KJElSw4zIHNaImAd0Anftx2EJ3BoR90TEhfWoq9ntWkDAeaySJGkMq3tgjYipwI3AhzNzw34c+orMPBk4B/hQRPz+AP1fGBGLImLR2rVrh6Hi5vH8w6cwbWKr81glSdKYVtfAGhHjqIbV6zPz+/tzbGauLm6fAm4CThmg3dWZuTAzF86aNetgS24qpVLQUSl7pQBJkjSm1fMqAQFcCyzPzCv289gpxYlaRMQU4CzgvuGvsvl1Vsr8+skNbN62s9GlSJIkNUQ9rxJwOvBOYFlELC22XQq0A2TmVRFxJLAImA70RMSHgfnA4cBN1cxLK/CtzPxhHWttWp3tbfQkLFvdxanPn9nociRJkkZc3QJrZt4J7PNaTJn5JDC3n10bgJPqUdeh5qRKGYAlK9YbWCVJ0pg0pCkBEXF0RLy2uD+p9+t61d9hU8Yzb+Zklq58ttGlSJIkNcSggTUiPgDcAPxjsWku8M/1LEp76qiUWbJiPZnZ6FIkSZJG3FBGWD9EdT7qBoDMfBh4Xj2L0p4629t4auM2nuja2uhSJEmSRtxQAuu2zNze+yAiWqle1F8jpKOYx+rlrSRJ0lg0lMD6HxFxKVBTW5sAAB4QSURBVDApIv4A+F/Av9S3LNU67qjpjG8tsWSF81glSdLYM5TAegmwFlgGfBC4BfhEPYvSnsa3llgwe7ojrJIkaUwa9LJWmdkDXFP8qEE629v45i9+y47uHsa11H1FXUmSpKYxlKsE/CYiHuv7MxLFabeOSpltO3v49ZMbG12KJEnSiBrKwgELa+5PBP4EOKw+5Wggne29Cwg8y4I5MxpcjSRJ0sgZdIQ1M9fV/KzOzM8Drx+B2lRjTnkSh0+dwBLnsUqSpDFm0BHWiDi55mGJ6ohr3ZZ0Vf8igs72MktXGFglSdLYMpTg+d9r7u8EHgfOr0s12qeOSpnbHvgd65/bTnny+EaXI0mSNCKGcpWAM0eiEA2udx7r0pXredVLXGxMkiSNDQMG1oj4L/s6MDOvGP5ytC8nzi0TYWCVJEljy75GWKeNWBUakqkTWnnx86axxHmskiRpDBkwsGbmp0ayEA1NZ3uZf7vvSTKTiGh0OZIkSXU3lKsETATeBxxP9TqsAGTme+tYlwbQUSnznbtX8punN/P8WVMbXY4kSVLdDWWNz28ARwKvA/4DmAu43FKDdLa3AdV5rJIkSWPBUALrCzPzvwGbM/N/Ul004OX1LUsDeeHzpjJlfIvzWCVJ0pgxlMC6o7hdHxELgBmAp6g3SEspOKlSdoRVkiSNGUMJrFdHRBvw34AfAA8An6lrVdqnjkqZ5U9sYOuO7kaXIkmSVHdDWenqa5nZTXX+6vPrXI+GoLO9jZ09yX2ru1g477BGlyNJklRXQxlh/U1EXB0Rrwmvo9QUOirVFa+cxypJksaCoQTWY4EfAx8CHo+IL0XEK+pblvZl1rQJzG2b5DxWSZI0JgwaWDPzucz8Xma+GegAplOdHqAG6vDEK0mSNEYMZYSViHhlRFwJ3EN18YDz61qVBtXZ3sbq9Vt4asPWRpciSZJUV4MG1oh4HPgwcAdwQmaen5k31rsw7duueayOskqSpFFuKFcJODEzN9S9Eu2X42dPZ1xLsGTFel53/JGNLkeSJKluhjKH1bDahCaOa2H+UdNZuvLZRpciSZJUV0Oaw6rm1Nnexr2ruujuyUaXIkmSVDcG1kNYR6XMc9u7eeh3GxtdiiRJUt0M5aSriyJielRdGxGLI+KskShO+9bZ7gICkiRp9BvKCOt7i3msZwFtwDuBy+talYak/bDJHDZlvPNYJUnSqDaUwNq7HOu5wDcy8/6abWqgiKCjUnaEVZIkjWpDCaz3RMStVAPrjyJiGtBT37I0VB2VMo+s3cSGrTsaXYokSVJdDCWwvg+4BHhZZj4HjAPeM9hBEVGJiJ9ExAMRcX9EXNRPm2Mj4ucRsS0iPtpn39kR8euIeCQiLhni6xlzOiplMuHelV2NLkWSJKkuhhJYTwN+nZnrI+IC4BPAUNLRTuAjmTkfOBX4UETM79PmGeAvgc/VboyIFuDLwDnAfOBt/Rwr4KRixSvnsUqSpNFqKIH1K8BzEXES8BHgUeCfBjsoM5/IzMXF/Y3AcmBOnzZPZebdQN/vs08BHsnMxzJzO/Ad4Lwh1DrmzJg0jhfMmuI8VkmSNGoNJbDuzMykGhi/lJlfBqbtz5NExDygE7hriIfMAVbWPF5Fn7Bb0/eFEbEoIhatXbt2f8oaNTrb21i6cj3VX5MkSdLoMpTAujEiPk71clY3R0SJ6jzWIYmIqcCNwIfrscxrZl6dmQszc+GsWbOGu/tDQkelzLrN21n5zJZGlyJJkjTshhJY3wJso3o91ieBucBnh9J5RIyjGlavz8zv70ddq4FKzeO5xTb1Y9cCAs5jlSRJo9CggbUIqdcDMyLiDcDWzBx0DmtEBHAtsDwzr9jPuu4GXhQRx0TEeOCtwA/2s48x4yVHTGPSuBbnsUqSpFGpdbAGEXE+1RHV26kuGPA/IuLizLxhkENPpzqNYFlELC22XQq0A2TmVRFxJLAImA70RMSHgfmZuSEi/gL4EdACXFcsWKB+tLaUOGHuDJauNLBKkqTRZ9DACvxXqtdgfQogImYBPwb2GVgz804GWRGrZopBf/tuAW4ZQn0COitlvvZ/H2fbzm4mtLY0uhxJkqRhM5Q5rKXesFpYN8TjNII628ts7+7hgTXDfl6bJElSQw1lhPWHEfEj4NvF47fgyGfT6ai0AbBkxXo629saXI0kSdLwGTSwZubFEfHHVOekAlydmTfVtyztryNnTOSoGROdxypJkkadoYywkpk3Ur08lZpYR6VsYJUkSaPOgHNRI2JjRGzo52djRDhRsgl1tpdZ8cxzrNu0rdGlSJIkDZsBA2tmTsvM6f38TMvM6SNZpIamdx6ro6ySJGk08Wz/UeSEOTNoKYULCEiSpFHFwDqKTBrfwrFHTnOEVZIkjSoG1lGms73Mr1aup6cnG12KJEnSsDCwjjIdlTY2btvJo2s3NboUSZKkYWFgHWU628sAzmOVJEmjhoF1lDlm5hSmT2xlifNYJUnSKGFgHWVKpaCjvY0lK55tdCmSJEnDwsA6CnVUyjz0u41s3raz0aVIkiQdNAPrKNRZKdOTcO+qrkaXIkmSdNAMrKNQR6V64pXXY5UkSaOBgXUUapsynnkzJzuPVZIkjQoG1lGqs72NJSvXk+kCApIk6dBmYB2lOipl1m7cxpqurY0uRZIk6aAYWEep3gUElrqAgCRJOsQZWEepY4+czvjWkvNYJUnSIc/AOkqNby1xwpwZXilAkiQd8gyso1hHpcyy1V3s6O5pdCmSJEkHzMA6inW2l9m2s4cHn9jY6FIkSZIOmIF1FOtdQGDJSuexSpKkQ5eBdRSbU57ErGkTvFKAJEk6pBlYR7GIoKNS9sQrSZJ0SDOwjnKd7WUee3oz65/b3uhSJEmSDoiBdZTrncfqKKskSTpUGVhHuRPnlikFLHEeqyRJOkQZWEe5qRNaefER0xxhlSRJhywD6xjQ2V498SozG12KJEnSfjOwjgEdlTJdW3bwm6c3N7oUSZKk/WZgHQM629sA57FKkqRDU90Ca0RUIuInEfFARNwfERf10yYi4osR8UhE3BsRJ9fs646IpcXPD+pV51jwgllTmTqh1XmskiTpkNRax753Ah/JzMURMQ24JyJuy8wHatqcA7yo+Hk58JXiFmBLZnbUsb4xo6UUnFSZ4RKtkiTpkFS3EdbMfCIzFxf3NwLLgTl9mp0H/FNW/QIoR8RR9appLOuolHnwiY1s2d7d6FIkSZL2y4jMYY2IeUAncFefXXOAlTWPV7E71E6MiEUR8YuIeNM++r6waLdo7dq1w1j16NJRaWNnT3Lfmq5GlyJJkrRf6h5YI2IqcCPw4czcsB+HHp2ZC4G3A5+PiBf01ygzr87MhZm5cNasWcNQ8ei0a8UrT7ySJEmHmLoG1ogYRzWsXp+Z3++nyWqgUvN4brGNzOy9fQy4neoIrQ7QrGkTmNs2yXmskiTpkFPPqwQEcC2wPDOvGKDZD4B3FVcLOBXoyswnIqItIiYU/RwOnA48MEAfGqLO9jZHWCVJ0iGnnlcJOB14J7AsIpYW2y4F2gEy8yrgFuBc4BHgOeA9RbvjgH+MiB6qofryPlcX0AHoqJT5l1+t4XcbtnLE9ImNLkeSJGlI6hZYM/NOIAZpk8CH+tn+M+CEOpU2ZnW2V+exLlmxnrMXHNngaiRJkobGla7GkPlHTWdcSziPVZIkHVIMrGPIxHEtzJ89w3mskiTpkGJgHWM6K2XuXdXFzu6eRpciSZI0JAbWMaazvcyWHd089LtNjS5FkiRpSAysY0zvAgLOY5UkSYcKA+sY037YZA6bMt55rJIk6ZBhYB1jIoKOSpmlKw2skiTp0GBgHYM6K2UeWbuJDVt3NLoUSZKkQRlYx6CO9jKZcO/KrkaXIkmSNCgD6xh0UqVMBCxZ4YlXkiSp+RlYx6DpE8fxgllTnccqSZIOCQbWMaqzUmbJyvVkZqNLkSRJ2icD6xjV0V7mmc3bWfnMlkaXIkmStE8G1jGqs9IGuICAJElqfgbWMerFR0xl0rgWlriAgCRJanIG1jGqtaXECXNnsMQTryRJUpMzsI5hne1llq/ZwLad3Y0uRZIkaUAG1jGss1Jme3cP96/Z0OhSJEmSBmRgHcM626snXi11HqskSWpiBtYx7IjpEzlqxkTnsUqSpKZmYB3jOtvLLPXSVpIkqYkZWMe4jkqZlc9s4elN2xpdiiRJUr8MrGOc81glSVKzM7COcQtmz6ClFK54JUmSmpaBdYybNL6F446axlJPvJIkSU3KwCo6KmV+tbKL7p5sdCmSJEl7MbCKzkobm7bt5NG1mxpdiiRJ0l4MrKKjvQzAkhXOY5UkSc3HwCqOmTmFGZPGOY9VkiQ1JQOrKJWCkypllnhpK0mS1IQMrAKgs1Lmod9tZPO2nY0uRZIkaQ8GVgHVeaw9Cfeu6mp0KZIkSXswsAqAjrnFiVcuICBJkpqMgVUAtE0ZzzGHT3GJVkmS1HTqFlgjohIRP4mIByLi/oi4qJ82ERFfjIhHIuLeiDi5Zt+fRsTDxc+f1qtO7dZZKbNk5XoyXUBAkiQ1j3qOsO4EPpKZ84FTgQ9FxPw+bc4BXlT8XAh8BSAiDgMuA14OnAJcFhFtdaxVVOexrt24jTVdWxtdiiRJ0i51C6yZ+URmLi7ubwSWA3P6NDsP+Kes+gVQjoijgNcBt2XmM5n5LHAbcHa9alVVZ6X6bwIXEJAkSc1kROawRsQ8oBO4q8+uOcDKmserim0DbVcdHXvUNCa0lpzHKkmSmkrdA2tETAVuBD6cmRvq0P+FEbEoIhatXbt2uLsfU8a1lFgwZwZLXPFKkiQ1kboG1ogYRzWsXp+Z3++nyWqgUvN4brFtoO17ycyrM3NhZi6cNWvW8BQ+hnVWyty3uovtO3saXYokSRJQ36sEBHAtsDwzrxig2Q+AdxVXCzgV6MrMJ4AfAWdFRFtxstVZxTbVWUd7mW07e3jwyWEfDJckSTogrXXs+3TgncCyiFhabLsUaAfIzKuAW4BzgUeA54D3FPueiYi/Ae4ujvt0Zj5Tx1pV6Gyvnni1dOV6TiwWE5AkSWqkugXWzLwTiEHaJPChAfZdB1xXh9K0D7NnTGTWtAksWbGed53W6GokSZJc6Up9RASdlTJLPfFKkiQ1CQOr9tLRXuY3T2/m2c3bG12KJEmSgVV7611AYOkqR1klSVLjGVi1lxPnzqAUsMQFBCRJUhMwsGovUya08uIjpjmPVZIkNQUDq/rV2V5m6Ypn6enJRpciSZLGOAOr+tVZaWPD1p38Zt3mRpciSZLGOAOr+tXRXl00wHmskiSp0Qys6tcLZ01l2oRWlq58ttGlSJKkMc7Aqn6VSsGJlRmeeCVJkhrOwKoBdVbaWP7ERrZs7250KZIkaQwzsGpAHZUy3T3JfWu6Gl2KJEkawwysGtDuE6+cxypJkhrHwKoBHT51ApXDJjmPVZIkNZSBVfvUWWnz0laSJKmhDKzap45KmSe6tvJk19ZGlyJJksYoA6v2qXceq9djlSRJjWJg1T4dP3s641tKLHEeqyRJahADq/ZpQmsLx82e7jxWSZLUMAZWDaqzUmbZqi52dvc0uhRJkjQGGVg1qM72Mlt2dPPr321sdCmSJGkMMrBqUJ2VNgCvxypJkhrCwKpBVQ6bxGFTxjuPVZIkNYSBVYOKCDorZUdYJUlSQxhYNSQdlTKPPLWJri07Gl2KJEkaYwysGpLO9uo81ntXOcoqSZJGloFVQ3JiZQYROI9VkiSNOAOrhmT6xHG8cNZU57FKkqQRZ2DVkHVUyixZ8SyZ2ehSJEnSGGJg1ZB1trfx7HM7WPHMc40uRZIkjSEGVg1ZR6UMOI9VkiSNLAOrhuzFR0xl8vgW57FKkqQRZWDVkLW2lDhhzgyWGFglSdIIMrBqv3S2t/HAmi627uhudCmSJGmMqFtgjYjrIuKpiLhvgP1tEXFTRNwbEb+MiAU1+x6PiGURsTQiFtWrRu2/jkqZHd3JA09saHQpkiRpjKjnCOvXgbP3sf9SYGlmngi8C/hCn/1nZmZHZi6sU306AJ3tnnglSZJGVt0Ca2b+FHhmH03mA/9etH0QmBcRR9SrHg2PI6ZPZPaMiZ54JUmSRkxrA5/7V8CbgTsi4hTgaGAu8DsggVsjIoF/zMyrG1em+upsb+Oex5/hrsfW0doStJRKtJaCllLU3JZoadn9eFyfx62lICIa/VIkSdIhoJGB9XLgCxGxFFgGLAF6z+R5RWaujojnAbdFxIPFiO1eIuJC4EKA9vb2ESi7cNtlsPoeaBlf/Izbj/v703Yf90st0IDQ97J5bdy87AnecvUvDqqfUlANtr1Bt6VP4C0Frbu29ROKBwzL1e3jWvZ83NrSf7s9+yvCdc3j/p4/onq/FFAqBaUIWiKIoNgetJSotovq41KJYnvRbtf2aj+9x1V/KNoZ6iVJalhgzcwNwHsAovp/5d8AjxX7Vhe3T0XETcApQL+BtRh9vRpg4cKFI7dmaAT0dMOOLujeDt07+tzW3t9WryKGMRgPve0FM1v5vT/cwY7upKenh56EnT3d9PRAT08P3Zn09CQ92UN3T9KTSU939ba7p6f6uDiue9dtcXz27Oqnb7vMpDuT3NFDdw9k0X9mFrc9u/vI3X3syGR7bx1FXZnQGwWrA/kQZJ93t3c7e+3P4lH1NujJoIdSsa1629PnNol+tu1+3FP0lQSZUTwGokSUSiRBRKkaYkslglL1NoBogShRiiCjRKkUEC1EUD2m+MdN7/HRu6/YXiq1QCkoRWlXP1EqFe1biJbeY6vHJzFs/1iq10q/9fxjEFRffvU2qp+RgCBqttc8Lhr0u6/og77bMylF9ZNSKj4hpeyhFEkpe2iJbiKTluKTsnt/D6VMSnQXx3ZX9+fuT1mJ7l2PS8UnM7Jov6vd7se7Po1RIqME0UIWn7nex0QLWSoeU4JSa/V+qQUIslRtQ6ml5phStZ9SiaB6W+27VLRrIfbY1lp9f0qx671i13tf87vo5z3e3XTP9z12d7HH72n3ttjrd0Z/z9H3+fr017ev2lp29dXnuXY/R3+fr71fK8E+9+/xXDWfs+pfJ4jsISJ3bSN7Bv4PdK///mP/9g9HH/3+DRqkjYMAh6yGBdaIKAPPZeZ24P3ATzNzQ0RMAUqZubG4fxbw6UbVOaDX/vXQ22ZWw+1eQfZg7u/ncTu3wbaNg7ft2THoy2kFXnyg71ujRPEz2i7k1tPoAqC7eFN3hW2AXRGn+sbnHvt3/+w6LmKP42uP66G0Vx+wO/RT+7wR/W/f33r2qGl3Pb099R/+sthW3deSNUFyj5+Bt/Ue00I1mKp/3VmN0z1FLK+N2N0172o3JXpq2ta2794dyXcfl9Xte7ct7fVpKfW53XM7lKL6H2e1st23vZ/Q2rbRp02JAY6NoTx39Tb72d+3XYufsX719Am9ff/27P23CthrW9+/M9U2u4/vvx01fdYe17ef6t+nofa5e7hlj/0R9P07mTVtIWh9w+c49uQzDvi9HE51C6wR8W3gVcDhEbEKuAwYB5CZVwHHAf+zmKd6P/C+4tAjgJuKEYdW4FuZ+cN61TkiIqCltfrD5EZXs2+ZQwvLPTvYPWSx+z/Y/h8zyP6hPD6YY2sc8PF9Hmcx+lA7CrFrNKLPtr3a9G7LftoMdNwAffXbNwO0Odi+a7fnrtsW+r72mttd9fTdt6/2tdvYz/a1+/anfc1I0r7aA70jg9UpOaU+91t2T9XZdb9Uc0ypz/G19/s5pnZ7v8fs+fzZO2IZ1SCWpRayGIlPSvSOaGZEcbt79DOpjoxm0TaLUc2MamirfqvUQ2Z39R/g2UP2VO/XbqOnu9qupxuyZlt2797WU/08Ru4ki/vsar97P7v67Sb22tazu/9d+3dCz+7R6NaebqK3PUn09lVzbOw6vs/j7CFy+677vd8qFHGUDIr3LIpR5eptbbvs/cfcrv1Rc0xtfKT4ne3+xxK938JEiZ21wWOPf9zVxM+oDSd797/Hbe++3LtdT/Ha6N2XvfXU6P3veiB7jcr2E4wHadMbm3q3Rk37rNlf29Ue29hzrLX6rdq+n3OgNlHzNyBq/i7tapu74x69UbHmb8Ye93vb5O77sccxu4vZo78+26LmeWtriezT5656+z7f7v5qY2qpT58TJ4yjWdQtsGbm2wbZ/3P6GajLzMeAk+pVlwYRAa3jqz+SDik1/7STpFFltH1BKkmSpFHGwCpJkqSmZmCVJElSUzOwSpIkqakZWCVJktTUDKySJElqagZWSZIkNTUDqyRJkpqagVWSJElNzcAqSZKkpmZglSRJUlMzsEqSJKmpGVglSZLU1CIzG13DsImItcBvR/ApDweeHsHnU/Pwdz82+Xsfu/zdj03+3kfW0Zk5q78doyqwjrSIWJSZCxtdh0aev/uxyd/72OXvfmzy9948nBIgSZKkpmZglSRJUlMzsB6cqxtdgBrG3/3Y5O997PJ3Pzb5e28SzmGVJElSU3OEVZIkSU3NwHqAIuLsiPh1RDwSEZc0uh7VX0RUIuInEfFARNwfERc1uiaNnIhoiYglEfGvja5FIyciyhFxQ0Q8GBHLI+K0RtekkRER/7n4W39fRHw7IiY2uqaxzMB6ACKiBfgycA4wH3hbRMxvbFUaATuBj2TmfOBU4EP+3seUi4DljS5CI+4LwA8z81jgJPwMjAkRMQf4S2BhZi4AWoC3Nraqsc3AemBOAR7JzMcyczvwHeC8BtekOsvMJzJzcXF/I9X/cc1pbFUaCRExF3g98NVG16KRExEzgN8HrgXIzO2Zub6xVWkEtQKTIqIVmAysaXA9Y5qB9cDMAVbWPF6FwWVMiYh5QCdwV2Mr0Qj5PPBXQE+jC9GIOgZYC3ytmA7y1YiY0uiiVH+ZuRr4HLACeALoysxbG1vV2GZglfZTREwFbgQ+nJkbGl2P6isi3gA8lZn3NLoWjbhW4GTgK5nZCWwGPGdhDIiINqrfnB4DzAamRMQFja1qbDOwHpjVQKXm8dxim0a5iBhHNaxen5nfb3Q9GhGnA2+MiMepTv95dUR8s7ElaYSsAlZlZu83KTdQDbAa/V4L/CYz12bmDuD7wO81uKYxzcB6YO4GXhQRx0TEeKoTsX/Q4JpUZxERVOeyLc/MKxpdj0ZGZn48M+dm5jyq/63/e2Y60jIGZOaTwMqIeEmx6TXAAw0sSSNnBXBqREwu/va/Bk+4a6jWRhdwKMrMnRHxF8CPqJ45eF1m3t/gslR/pwPvBJZFxNJi26WZeUsDa5JUX/8JuL4YnHgMeE+D69EIyMy7IuIGYDHVK8QswVWvGsqVriRJktTUnBIgSZKkpmZglSRJUlMzsEqSJKmpGVglSZLU1AyskiRJamoGVkkaRhHxs+J2XkS8fZj7vrS/55Kk0c7LWklSHUTEq4CPZuYb9uOY1szcuY/9mzJz6nDUJ0mHEkdYJWkYRcSm4u7lwBkRsTQi/nNEtETEZyPi7oi4NyI+WLR/VUTcERE/oFhFKSL+OSLuiYj7I+LCYtvlwKSiv+trnyuqPhsR90XEsoh4S03ft0fEDRHxYERcX6zaQ0RcHhEPFLV8biTfI0naX650JUn1cQk1I6xF8OzKzJdFxATg/0bErUXbk4EFmfmb4vF7M/OZiJgE3B3x/7d3x65VQ2EYxp9vEApaKqijoINScOh1UCyKkzg5aBcHwVlBBR3Ef8NVENxcFHGROqoI2qHYLuIuojiIiEWR6+twcyXI7eLtvWR4fhBIcnKSnO3l5EtSD5PcqqorSXojrrUE9IAFYHfT53nTdhg4BHwAXgLHq+otcA6YT5Kq2rnlo5ekLeQMqyRNx2ngYvNb39fALuBA07bSCqsA16pqDXgF7G0dt5kTwP0k/SSfgGfAkda53yf5DbwB9gFfgR/A3apaAjbGHp0kTZCBVZKmo4CrSXrNsj/JcIb1+9+DBrWvp4DFJAsM/mE+M8Z1f7bW+8CwTvYo8AA4AyyPcX5JmjgDqyRNxjdgtrX9FLhcVdsAqupgVW0f0W8O+JJko6rmgWOttl/D/v94AZxv6mT3ACeBlc1urKp2AHNJngDXGZQSSFJnWcMqSZOxDvSbR/v3gNsMHsevNi8+fQbOjui3DFxq6kzfMSgLGLoDrFfVapILrf2PgEVgDQhwM8nHJvCOMgs8rqoZBjO/N/5viJI0HX7WSpIkSZ1mSYAkSZI6zcAqSZKkTjOwSpIkqdMMrJIkSeo0A6skSZI6zcAqSZKkTjOwSpIkqdMMrJIkSeq0P4UixgHRNROpAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Plot the loss curve for the model training\n",
        "def show_loss(train_loss, test_loss):\n",
        "  fig = plt.figure(figsize=(12,6))\n",
        "  plt.subplots_adjust(bottom=0.2,right=0.85,top=0.95)\n",
        "  ax = fig.add_subplot(1,1,1)\n",
        "\n",
        "  ax.clear()\n",
        "  ax.set_xlabel('iterations')\n",
        "  ax.set_ylabel('loss value')\n",
        "  ax.set_title('loss curve for model vs. epochs')\n",
        "  ax.plot(train_loss, label='training loss')\n",
        "  ax.plot(test_loss, label='testing loss')\n",
        "  ax.legend(loc='upper right')\n",
        "  fig.canvas.draw()\n",
        "\n",
        "show_loss(train_loss, test_loss)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the accuracy curve for the model training\n",
        "# def show_accu(accu_list):\n",
        "#   fig = plt.figure(figsize=(12,6))\n",
        "#   plt.subplots_adjust(bottom=0.2,right=0.85,top=0.95)\n",
        "#   ax = fig.add_subplot(1,1,1)\n",
        "\n",
        "#   ax.clear()\n",
        "#   ax.set_xlabel('iterations')\n",
        "#   ax.set_ylabel('accuracy value')\n",
        "#   ax.set_title('Testing accuracy curve for model')\n",
        "#   ax.plot(accu_list, label='testing accuracy')\n",
        "#   ax.legend(loc='upper right')\n",
        "#   fig.canvas.draw()\n",
        "\n",
        "# show_accu(test_accu)"
      ],
      "metadata": {
        "id": "KoxxI36rXiQY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IccxDCBWN4KC"
      },
      "source": [
        "## **Part 5: Unsupervised training**\n",
        "In this section, we will use unsupervised training to detect K+N classes and the labels for the newly added N classes are removed.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **(a). Encoder**<br>\n",
        "The encoder can extract the features output by the model using include_top = False. Then the decoder will do operations including pca and k means to cluster the K+N classes using those features. \n"
      ],
      "metadata": {
        "id": "r2_52RLPH8ms"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PqM-46FaOSxP"
      },
      "outputs": [],
      "source": [
        "# Given a (pre-trained) model, encode the data into its latent space\n",
        "def encoder(model, data):\n",
        "  model.eval()\n",
        "  output = []\n",
        "  with torch.no_grad():\n",
        "    for image in data:\n",
        "      x = image[None,None].type(torch.FloatTensor).to(device)\n",
        "      output.append(model(x, include_top=False).cpu().numpy())\n",
        "  output = np.array(output)\n",
        "  output = np.reshape(output, (output.shape[0], output.shape[2]))\n",
        "  return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9w0DDXZyHHGw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1f50091-2847-4070-f2bd-a05efe8b224d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 1936)\n",
            "(18000, 1936)\n"
          ]
        }
      ],
      "source": [
        "trainX_encoded = encoder(model, train_X_orig)\n",
        "print(trainX_encoded.shape)\n",
        "trainX2_encoded = encoder(model, train_uX_orig)\n",
        "print(trainX2_encoded.shape)\n",
        "untrainedX2_encoded = encoder(untrained_model, train_uX_orig)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvXbiA3RC-z_"
      },
      "source": [
        "### **(b).Decoder**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fX_TCNUWG3HC"
      },
      "outputs": [],
      "source": [
        "class Decoder:\n",
        "\n",
        "  def get_pca(self, X, n):\n",
        "    model_pca = PCA(n_components=n)\n",
        "    output = model_pca.fit_transform(X)\n",
        "    return output.astype('float32')\n",
        "\n",
        "\n",
        "  def get_kmeans(self, X, k):\n",
        "    model_kmeans = KMeans(n_clusters=k, random_state=484)\n",
        "\n",
        "    start = time.time()\n",
        "    output = model_kmeans.fit_predict(X)\n",
        "    end = time.time()\n",
        "\n",
        "    print(\"K-Means Algorithm took {} seconds\".format(end-start))\n",
        "    return output\n",
        "\n",
        "  def get_gmm(self, data, k):\n",
        "      g = GaussianMixture(n_components=k, covariance_type=\"full\", random_state=728)\n",
        "      \n",
        "      start=time.time()\n",
        "      g.fit(data)\n",
        "      end=time.time()\n",
        "      \n",
        "      print(\"GMM Algorithm took {} seconds\".format(end-start))\n",
        "      \n",
        "      return g\n",
        "      \n",
        "  def decode(self, data_encoded, pca_components=50, k = len(classes)):\n",
        "    pca_fit = self.get_pca(data_encoded, n=pca_components)\n",
        "    kmeans_pred = self.get_kmeans(pca_fit, k)\n",
        "    # gmm_pred = self.get_gmm(pca_fit, k)\n",
        "    return kmeans_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0vUOnHR-G_7o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0429737e-c965-47ab-cc45-7ef0ab457d77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_pca.py:595: RuntimeWarning: invalid value encountered in true_divide\n",
            "  self.explained_variance_ratio_ = self.explained_variance_ / total_var.sum()\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1258: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "K-Means Algorithm took 1.6901459693908691 seconds\n",
            "K-Means Algorithm took 5.901529788970947 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_pca.py:595: RuntimeWarning: invalid value encountered in true_divide\n",
            "  self.explained_variance_ratio_ = self.explained_variance_ / total_var.sum()\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py:1258: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
            "  return self.fit(X, sample_weight=sample_weight).labels_\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "K-Means Algorithm took 0.5924022197723389 seconds\n",
            "K-Means Algorithm took 2.432239055633545 seconds\n",
            "K-Means Algorithm took 1.9480869770050049 seconds\n"
          ]
        }
      ],
      "source": [
        "decoder = Decoder()\n",
        "trainX_mpred = decoder.decode(trainX_encoded)\n",
        "trainX_pred = decoder.decode(trainX_flatten)\n",
        "trainX2_mpred = decoder.decode(trainX2_encoded)\n",
        "trainX2_pred = decoder.decode(trainX2_flatten)\n",
        "untrainedX2_pred = decoder.decode(untrainedX2_encoded)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6bA34Q4mgPM"
      },
      "source": [
        "### **(c). Count clusters and seperate them.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qu2JGd1mIuHi"
      },
      "outputs": [],
      "source": [
        "def cluster_label_count(clusters, labels):  \n",
        "    count = {}\n",
        "    \n",
        "    # Get unique clusters and labels\n",
        "    unique_clusters = list(set(clusters))\n",
        "    unique_labels = list(classes)\n",
        "\n",
        "    # Create counter for each cluster/label combination and set it to 0\n",
        "    for cluster in unique_clusters:\n",
        "        count[cluster] = {}\n",
        "        \n",
        "        for label in unique_labels:\n",
        "            count[cluster][label] = 0\n",
        "\n",
        "    # Let's count\n",
        "    for i in range(len(clusters)):\n",
        "      idx = labels[i].item()\n",
        "      count[clusters[i]][unique_labels[idx]] +=1\n",
        "    \n",
        "    cluster_df = pd.DataFrame(count)\n",
        "    \n",
        "    return cluster_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fGPgp7zWmy1F"
      },
      "outputs": [],
      "source": [
        "trainX_mcluster = cluster_label_count(trainX_mpred, train_y_orig)\n",
        "trainX_cluster = cluster_label_count(trainX_pred, train_y_orig)\n",
        "\n",
        "trainX2_mcluster = cluster_label_count(trainX2_mpred, train_uy_orig)\n",
        "trainX2_cluster = cluster_label_count(trainX2_pred, train_uy_orig)\n",
        "\n",
        "untrainX2_cluster = cluster_label_count(untrainedX2_pred, train_uy_orig)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3XRgIcdbxxDH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "outputId": "4f5f24bc-c6a4-4428-b815-ad92a8e713df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model + KMeans Cluster (full trainset):\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-16a124fc-e4b3-4070-8168-2a0aa7c3448e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Ankle boot</th>\n",
              "      <td>6000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Bag</th>\n",
              "      <td>6000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Coat</th>\n",
              "      <td>6000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Dress</th>\n",
              "      <td>6000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Pullover</th>\n",
              "      <td>6000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sandal</th>\n",
              "      <td>6000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Shirt</th>\n",
              "      <td>6000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sneaker</th>\n",
              "      <td>6000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>T-shirt/top</th>\n",
              "      <td>6000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Trouser</th>\n",
              "      <td>6000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-16a124fc-e4b3-4070-8168-2a0aa7c3448e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-16a124fc-e4b3-4070-8168-2a0aa7c3448e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-16a124fc-e4b3-4070-8168-2a0aa7c3448e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                0\n",
              "Ankle boot   6000\n",
              "Bag          6000\n",
              "Coat         6000\n",
              "Dress        6000\n",
              "Pullover     6000\n",
              "Sandal       6000\n",
              "Shirt        6000\n",
              "Sneaker      6000\n",
              "T-shirt/top  6000\n",
              "Trouser      6000"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "print(\"Model + KMeans Cluster (full trainset):\")\n",
        "trainX_mcluster"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"KMeans Cluster (full trainset):\")\n",
        "trainX_cluster"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "id": "ZA96kNoSc4jP",
        "outputId": "bcae8bc9-f060-45f6-9d19-588236af97c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KMeans Cluster (full trainset):\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-3ef770ea-df9f-47fb-83a4-d39f5764166a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>T-shirt/top</th>\n",
              "      <td>2</td>\n",
              "      <td>624</td>\n",
              "      <td>207</td>\n",
              "      <td>3401</td>\n",
              "      <td>0</td>\n",
              "      <td>1551</td>\n",
              "      <td>0</td>\n",
              "      <td>163</td>\n",
              "      <td>29</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Trouser</th>\n",
              "      <td>0</td>\n",
              "      <td>158</td>\n",
              "      <td>5414</td>\n",
              "      <td>234</td>\n",
              "      <td>0</td>\n",
              "      <td>128</td>\n",
              "      <td>0</td>\n",
              "      <td>63</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Pullover</th>\n",
              "      <td>1</td>\n",
              "      <td>536</td>\n",
              "      <td>9</td>\n",
              "      <td>114</td>\n",
              "      <td>0</td>\n",
              "      <td>1791</td>\n",
              "      <td>0</td>\n",
              "      <td>3496</td>\n",
              "      <td>26</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Dress</th>\n",
              "      <td>0</td>\n",
              "      <td>545</td>\n",
              "      <td>3222</td>\n",
              "      <td>1677</td>\n",
              "      <td>0</td>\n",
              "      <td>495</td>\n",
              "      <td>0</td>\n",
              "      <td>49</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Coat</th>\n",
              "      <td>0</td>\n",
              "      <td>259</td>\n",
              "      <td>160</td>\n",
              "      <td>868</td>\n",
              "      <td>0</td>\n",
              "      <td>1091</td>\n",
              "      <td>0</td>\n",
              "      <td>3577</td>\n",
              "      <td>29</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sandal</th>\n",
              "      <td>1481</td>\n",
              "      <td>3720</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>490</td>\n",
              "      <td>28</td>\n",
              "      <td>261</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Shirt</th>\n",
              "      <td>7</td>\n",
              "      <td>800</td>\n",
              "      <td>64</td>\n",
              "      <td>1050</td>\n",
              "      <td>0</td>\n",
              "      <td>2063</td>\n",
              "      <td>1</td>\n",
              "      <td>1935</td>\n",
              "      <td>17</td>\n",
              "      <td>63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sneaker</th>\n",
              "      <td>4685</td>\n",
              "      <td>492</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>796</td>\n",
              "      <td>0</td>\n",
              "      <td>26</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Bag</th>\n",
              "      <td>240</td>\n",
              "      <td>512</td>\n",
              "      <td>28</td>\n",
              "      <td>22</td>\n",
              "      <td>68</td>\n",
              "      <td>188</td>\n",
              "      <td>6</td>\n",
              "      <td>264</td>\n",
              "      <td>2451</td>\n",
              "      <td>2221</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ankle boot</th>\n",
              "      <td>160</td>\n",
              "      <td>170</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2934</td>\n",
              "      <td>37</td>\n",
              "      <td>2689</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3ef770ea-df9f-47fb-83a4-d39f5764166a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3ef770ea-df9f-47fb-83a4-d39f5764166a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3ef770ea-df9f-47fb-83a4-d39f5764166a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                0     1     2     3     4     5     6     7     8     9\n",
              "T-shirt/top     2   624   207  3401     0  1551     0   163    29    23\n",
              "Trouser         0   158  5414   234     0   128     0    63     0     3\n",
              "Pullover        1   536     9   114     0  1791     0  3496    26    27\n",
              "Dress           0   545  3222  1677     0   495     0    49     7     5\n",
              "Coat            0   259   160   868     0  1091     0  3577    29    16\n",
              "Sandal       1481  3720     1     2   490    28   261     0    13     4\n",
              "Shirt           7   800    64  1050     0  2063     1  1935    17    63\n",
              "Sneaker      4685   492     0     0   796     0    26     0     0     1\n",
              "Bag           240   512    28    22    68   188     6   264  2451  2221\n",
              "Ankle boot    160   170     3     2  2934    37  2689     1     0     4"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UkBYdPshI8jY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "outputId": "c96f3521-01d0-4436-8758-4f7fffe0cef8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model + KMeans Cluster (unseen trainset):\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-b838d44b-7bfa-46c0-8793-c836c6a3928a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Ankle boot</th>\n",
              "      <td>6000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Bag</th>\n",
              "      <td>6000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Coat</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Dress</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Pullover</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sandal</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Shirt</th>\n",
              "      <td>6000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sneaker</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>T-shirt/top</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Trouser</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b838d44b-7bfa-46c0-8793-c836c6a3928a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b838d44b-7bfa-46c0-8793-c836c6a3928a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b838d44b-7bfa-46c0-8793-c836c6a3928a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                0\n",
              "Ankle boot   6000\n",
              "Bag          6000\n",
              "Coat            0\n",
              "Dress           0\n",
              "Pullover        0\n",
              "Sandal          0\n",
              "Shirt        6000\n",
              "Sneaker         0\n",
              "T-shirt/top     0\n",
              "Trouser         0"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "print(\"Model + KMeans Cluster (unseen trainset):\")\n",
        "trainX2_mcluster"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kck0QAFh6LjD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "outputId": "8f59866d-085c-4b83-bcde-84892f74200e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KMeans Cluster (unseen trainset):\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-376d2595-cdd2-4c76-bb8c-967749e2e0ca\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>T-shirt/top</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Trouser</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Pullover</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Dress</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Coat</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sandal</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Shirt</th>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>1489</td>\n",
              "      <td>0</td>\n",
              "      <td>1210</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>1528</td>\n",
              "      <td>38</td>\n",
              "      <td>1715</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sneaker</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Bag</th>\n",
              "      <td>143</td>\n",
              "      <td>1341</td>\n",
              "      <td>88</td>\n",
              "      <td>4</td>\n",
              "      <td>27</td>\n",
              "      <td>1367</td>\n",
              "      <td>2</td>\n",
              "      <td>303</td>\n",
              "      <td>2024</td>\n",
              "      <td>701</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ankle boot</th>\n",
              "      <td>1953</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>2233</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1622</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>178</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-376d2595-cdd2-4c76-bb8c-967749e2e0ca')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-376d2595-cdd2-4c76-bb8c-967749e2e0ca button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-376d2595-cdd2-4c76-bb8c-967749e2e0ca');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                0     1     2     3     4     5     6     7     8     9\n",
              "T-shirt/top     0     0     0     0     0     0     0     0     0     0\n",
              "Trouser         0     0     0     0     0     0     0     0     0     0\n",
              "Pullover        0     0     0     0     0     0     0     0     0     0\n",
              "Dress           0     0     0     0     0     0     0     0     0     0\n",
              "Coat            0     0     0     0     0     0     0     0     0     0\n",
              "Sandal          0     0     0     0     0     0     0     0     0     0\n",
              "Shirt           1     6  1489     0  1210    12     1  1528    38  1715\n",
              "Sneaker         0     0     0     0     0     0     0     0     0     0\n",
              "Bag           143  1341    88     4    27  1367     2   303  2024   701\n",
              "Ankle boot   1953     0     6  2233     3     0  1622     2     3   178"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "print(\"KMeans Cluster (unseen trainset):\")\n",
        "trainX2_cluster"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uovbQlsyOaE4"
      },
      "source": [
        "## **Part 6: Validation of Unsupervised training**\n",
        "In this part, we will do qualitative and quantitative evaluation of predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bVjJXpt1Oi-z"
      },
      "outputs": [],
      "source": [
        "# # the seen and unseen class clustering score\n",
        "# trainX_m_score = homogeneity_score(trainX_mpred, train_y_orig)\n",
        "# print(\"2-step (Model+Kmeans) training accuracy on all classes: \", trainX_m_score)\n",
        "# trainX_score = homogeneity_score(trainX_pred, train_y_orig)\n",
        "# print(\"K means accuracy on all classes: \",  trainX_score)\n",
        "\n",
        "# print(\"\")\n",
        "\n",
        "# # the unseen class clustering score\n",
        "# trainX2_m_score = homogeneity_score(trainX2_mpred, train_uy_orig)\n",
        "# print(\"2-step (Model+Kmeans) training accuracy on unseen classes: \" + str(trainX2_m_score))\n",
        "# trainX2_score = homogeneity_score(trainX2_pred, train_uy_orig)\n",
        "# print(\"K means accuracy on unseen classes: \" + str(trainX2_score))\n",
        "# untrainedX2_score = homogeneity_score(untrainedX2_pred, train_uy_orig)\n",
        "# print(\"Untrained accuracy on unseen classes: \" + str(untrainedX2_score))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_UVJM1ys1xh5"
      },
      "source": [
        "### **(a). Evaluation method for k-means clustering result** <br>\n",
        "\n",
        " The following methods that we use are all external critertion that evaluates the performance of clustering compare to the ground truth labels.\n",
        "\n",
        "\n",
        "1.   Manually assign label to cluster\n",
        "2.   Purity\n",
        "3.   Rand Index / Ajusted Rand Index\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Manually assign label to cluster**\n",
        "\n",
        "> This algorithm works same as how human assign label to cluster. In the first step, it will choose the index $(i,j)$ where element in $(i,j)$ is the max value within $i$th row or $j$th column.\n",
        "\n",
        "> As each cluster should only be assigned one label, second step deals with the confusing label and cluster pairs. It will traverse all possible combination of the remaining label and cluster pairs. Ans choose the combination that will give max accuracy level."
      ],
      "metadata": {
        "id": "ARt7oSqvoiQO"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bCtUCCagj5W"
      },
      "source": [
        "**Purity**\n",
        "\n",
        "  Purity measures the number of percentage of the labels that are clustered correctly. \n",
        "\n",
        "$$Purity = \\frac{1}{N} \\sum_{i=1}^{k} max_j|c_i \\cap t_j|$$\n",
        "\n",
        "  \n",
        "\n",
        "> where $N$ stands for the total number of objects(data) in the dataset, $k$ is the number of clusters and $c_i$ one cluster in $C$ and $t_j$ is the class label. The equation $max_j|c_i \\cap t_j|$ represent the class $j$ which has the max count in cluster $c_i$.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Xa_K4GryXHQ"
      },
      "source": [
        "**Ajusted Rand Index**\n",
        "\n",
        "  Rand Index measures the similarity between two clusterings. It also computes the percentage of correct pairs using the following equation.\n",
        "\n",
        "$$RI = \\frac{\\text{number of agreeing pairs}}{\\text{number of pairs}}$$\n",
        "\n",
        "\n",
        "\n",
        "> In our evaluation, we will be using the rand index ajusted for chance. Ajusted Rand Index is often used when the ground truth clustering are about the same size which matches our dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IQykzgC81rW4"
      },
      "outputs": [],
      "source": [
        "class evaluation:\n",
        "\n",
        "  def __init__(self, result_matrix):\n",
        "    self.result_matrix = result_matrix\n",
        "    self.num_object = np.sum(result_matrix)\n",
        "    self.class_label = np.argmax(result_matrix, axis = 1) # get the the label \n",
        "    self.num_correct_label = np.max(result_matrix, axis = 1) # get number of corrected labeling\n",
        "\n",
        "  def manual_assign_label_cluster(self):\n",
        "    row_index = self.result_matrix.argmax(axis=1)\n",
        "    col_index = self.result_matrix.argmax(axis=0)\n",
        "    accu_pred = 0\n",
        "\n",
        "    index_pair = {}\n",
        "    class_arr = np.array(list(range(0, len(row_index))))\n",
        "\n",
        "    # Step 1\n",
        "    for i in range(len(row_index)):\n",
        "      if(col_index[row_index[i]] == i):\n",
        "          index_pair[i] = row_index[i]\n",
        "          accu_pred += self.result_matrix[i][row_index[i]]\n",
        "\n",
        "    non_match_class = list(set(class_arr) - set(index_pair.keys()))\n",
        "    non_match_cluster = list(set(class_arr) - set(index_pair.values()))\n",
        "\n",
        "    sum_accu = 0\n",
        "    remaining_pair = []\n",
        "\n",
        "    # Step 2\n",
        "    if(len(index_pair)<len(row_index)):\n",
        "      # pair_arr sample: [[(5, 0), (6, 3)], [(6, 0), (5, 3)]]\n",
        "      pair_arr = [list(zip(x,non_match_cluster)) for x in itertools.permutations(non_match_class,len(non_match_cluster))]\n",
        "      for pair in pair_arr:\n",
        "        accu = 0\n",
        "        for index_tuple in pair:\n",
        "          accu += self.result_matrix[index_tuple[0]][index_tuple[1]]\n",
        "        if accu >= sum_accu:\n",
        "          sum_accu = accu\n",
        "          remaining_pair = pair\n",
        "\n",
        "    accu_pred += sum_accu\n",
        "    for t in remaining_pair:\n",
        "      index_pair[t[0]] = t[1]\n",
        "\n",
        "    return accu_pred/np.sum(self.result_matrix), index_pair\n",
        "\n",
        "\n",
        "  def eval_purity(self):\n",
        "    total_correct_label = np.sum(self.num_correct_label)\n",
        "    num_object = self.num_object\n",
        "    return total_correct_label / self.num_object\n",
        "  \n",
        "\n",
        "  def eval_ajusted_rand_index(self, gt, predict):\n",
        "    return adjusted_rand_score(gt, predict)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval = evaluation(trainX_cluster.to_numpy())\n",
        "accu_kmean, pair_list_kmean = eval.manual_assign_label_cluster()\n",
        "label_cluster_kpair = {}\n",
        "for key in pair_list_kmean:\n",
        "  label_cluster_kpair[classes[key]] = pair_list_kmean[key]\n",
        "\n",
        "print(\"Only using Kmean (without model) result is:\")\n",
        "print(trainX_cluster)\n",
        "print(\"\\nThe assigned label and cluster pair is:\")\n",
        "print(label_cluster_kpair)\n",
        "print(\"\\nAccuracy Checking by assigning labels to clusters is: \", accu_kmean)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_bI2WMf0mgYu",
        "outputId": "b7aaf100-3183-4344-83d1-b7826a04ddfb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Only using Kmean (without model) result is:\n",
            "                0     1     2     3     4     5     6     7     8     9\n",
            "T-shirt/top     2   624   207  3401     0  1551     0   163    29    23\n",
            "Trouser         0   158  5414   234     0   128     0    63     0     3\n",
            "Pullover        1   536     9   114     0  1791     0  3496    26    27\n",
            "Dress           0   545  3222  1677     0   495     0    49     7     5\n",
            "Coat            0   259   160   868     0  1091     0  3577    29    16\n",
            "Sandal       1481  3720     1     2   490    28   261     0    13     4\n",
            "Shirt           7   800    64  1050     0  2063     1  1935    17    63\n",
            "Sneaker      4685   492     0     0   796     0    26     0     0     1\n",
            "Bag           240   512    28    22    68   188     6   264  2451  2221\n",
            "Ankle boot    160   170     3     2  2934    37  2689     1     0     4\n",
            "\n",
            "The assigned label and cluster pair is:\n",
            "{'T-shirt/top': 3, 'Trouser': 2, 'Coat': 7, 'Sandal': 1, 'Shirt': 5, 'Sneaker': 0, 'Bag': 8, 'Ankle boot': 4, 'Pullover': 9, 'Dress': 6}\n",
            "\n",
            "Accuracy Checking by assigning labels to clusters is:  0.4712\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "htZVE4IOQit9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b46ebe95-871a-4e16-a86e-fd650c3319c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Only using Kmean (without model) result is:\n",
            "Purity is  0.5827166666666667\n",
            "Ajusted rand index is 0.34689076627447957\n"
          ]
        }
      ],
      "source": [
        "trainX_matrix = trainX_cluster.to_numpy()\n",
        "eval_k = evaluation(trainX_matrix)\n",
        "print(\"Only using Kmean (without model) result is:\")\n",
        "\n",
        "# evaluate purity\n",
        "purity = eval_k.eval_purity()\n",
        "print(\"Purity is  \" + str(purity))\n",
        "\n",
        "# evaluate rand index (Ajusted)\n",
        "ajusted_rand_index = eval_k.eval_ajusted_rand_index(trainX_pred, train_y_orig)\n",
        "print(\"Ajusted rand index is \" + str(ajusted_rand_index))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_ck = evaluation(trainX_mcluster.to_numpy())\n",
        "accu, pair_list = eval_ck.manual_assign_label_cluster()\n",
        "\n",
        "label_cluster_pair = {}\n",
        "for key in pair_list:\n",
        "  label_cluster_pair[classes[key]] = pair_list[key]\n",
        "\n",
        "print(\"Model + Kmean clustering result is:\")\n",
        "print(trainX_mcluster)\n",
        "print(\"\\nThe assigned label and cluster pair is:\")\n",
        "print(label_cluster_pair)\n",
        "print(\"\\nAccuracy Checking by assigning labels to clusters is: \", accu)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "id": "BJvjzU3SnC7b",
        "outputId": "cccc34e8-ff55-45ec-d56a-136ff1a635b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-b72190bc88b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0meval_ck\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX_mcluster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0maccu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpair_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_ck\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_assign_label_cluster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlabel_cluster_pair\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpair_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-29-e10b7cc79a23>\u001b[0m in \u001b[0;36mmanual_assign_label_cluster\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0maccu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mindex_tuple\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpair\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m           \u001b[0maccu\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex_tuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex_tuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maccu\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0msum_accu\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m           \u001b[0msum_accu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for axis 0 with size 1"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tVDONv5lgpqn"
      },
      "outputs": [],
      "source": [
        "trainX_cluster_matrix = trainX_mcluster.to_numpy()\n",
        "eval = evaluation(trainX_cluster_matrix)\n",
        "print(\"Model + Kmean clustering result is:\")\n",
        "\n",
        "# evaluate purity\n",
        "purity = eval.eval_purity()\n",
        "print(\"Purity is  \" + str(purity))\n",
        "\n",
        "# evaluate rand index (Ajusted)\n",
        "ajusted_rand_index = eval.eval_ajusted_rand_index(trainX_mpred, train_y_orig)\n",
        "print(\"Ajusted rand index is \" + str(ajusted_rand_index))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**(aa) Summery of different dataset**"
      ],
      "metadata": {
        "id": "-PFWbtrnr1SQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"===========================================================\")\n",
        "# trainX_mcluster = cluster_label_count(trainX_mpred, train_y_orig)\n",
        "eval = evaluation(trainX_mcluster.to_numpy())\n",
        "accu, pair_list = eval.manual_assign_label_cluster()\n",
        "purity = eval.eval_purity()\n",
        "ajusted_rand_index = eval.eval_ajusted_rand_index(trainX_mpred, train_y_orig)\n",
        "print(\"Evaluation for data with trained model + Kmean clustering (Seen label):\")\n",
        "print(\"Manural Assign Label accu: \", accu)\n",
        "print(\"Purity: \", purity)\n",
        "print(\"Adjust Random Index: \", ajusted_rand_index)\n",
        "print(\"===========================================================\")\n",
        "\n",
        "# trainX_cluster = cluster_label_count(trainX_pred, train_y_orig)\n",
        "eval = evaluation(trainX_cluster.to_numpy())\n",
        "accu, pair_list = eval.manual_assign_label_cluster()\n",
        "purity = eval.eval_purity()\n",
        "ajusted_rand_index = eval.eval_ajusted_rand_index(trainX_pred, train_y_orig)\n",
        "print(\"Evaluation for data with only Kmean clustering (Seen label):\")\n",
        "print(\"Manural Assign Label accu: \", accu)\n",
        "print(\"Purity: \", purity)\n",
        "print(\"Adjust Random Index: \", ajusted_rand_index)\n",
        "print(\"===========================================================\")\n",
        "\n",
        "# trainX2_mcluster = cluster_label_count(trainX2_mpred, train_uy_orig)\n",
        "eval = evaluation(trainX2_mcluster.to_numpy())\n",
        "accu, pair_list = eval.manual_assign_label_cluster()\n",
        "purity = eval.eval_purity()\n",
        "ajusted_rand_index = eval.eval_ajusted_rand_index(trainX2_mpred, train_uy_orig)\n",
        "print(\"Evaluation for data with trained model + Kmean clustering (Unseen label):\")\n",
        "print(\"Manural Assign Label accu: \", accu)\n",
        "print(\"Purity: \", purity)\n",
        "print(\"Adjust Random Index: \", ajusted_rand_index)\n",
        "print(\"===========================================================\")\n",
        "\n",
        "# trainX2_cluster = cluster_label_count(trainX2_pred, train_uy_orig)\n",
        "eval = evaluation(trainX2_cluster.to_numpy())\n",
        "accu, pair_list = eval.manual_assign_label_cluster()\n",
        "purity = eval.eval_purity()\n",
        "ajusted_rand_index = eval.eval_ajusted_rand_index(trainX2_pred, train_uy_orig)\n",
        "print(\"Evaluation for data with only Kmean clustering (Unseen label):\")\n",
        "print(\"Manural Assign Label accu: \", accu)\n",
        "print(\"Purity: \", purity)\n",
        "print(\"Adjust Random Index: \", ajusted_rand_index)\n",
        "print(\"===========================================================\")\n",
        "\n",
        "# untrainX2_cluster = cluster_label_count(untrainedX2_pred, train_uy_orig)\n",
        "eval = evaluation(untrainX2_cluster.to_numpy())\n",
        "accu, pair_list = eval.manual_assign_label_cluster()\n",
        "purity = eval.eval_purity()\n",
        "ajusted_rand_index = eval.eval_ajusted_rand_index(untrainedX2_pred, train_uy_orig)\n",
        "print(\"Evaluation for data with Untrained model + Kmean clustering (Unseen label):\")\n",
        "print(\"Manural Assign Label accu: \", accu)\n",
        "print(\"Purity: \", purity)\n",
        "print(\"Adjust Random Index: \", ajusted_rand_index)\n",
        "print(\"===========================================================\")\n"
      ],
      "metadata": {
        "id": "8j1M-ZO7sAfh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Summary: We could see that comparing the first two, we get around 7-10% improvement for each accuracy if we use 2-step method (trained model + Kmean). Comparing 3rd and 4th result, we could see that for unseen class only, the improvement is also around 7-10%. Comparing 3rd and 5th, we coud see that the accuracy of 2-step (unseen class) using trained model is better than fully untrained model, which means our training do have improvement for unseen classes."
      ],
      "metadata": {
        "id": "AkG9XVqkzkli"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **(b). Evaluate results based on the pca values**\n",
        "\n",
        "This part will do the above evaluations, but the pca value will change."
      ],
      "metadata": {
        "id": "RpjOIzWvqE-_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluation_results(model, data, data_y, pca_val):\n",
        "  encode_data = encoder(model, data)\n",
        "  # initialize decoder\n",
        "  decoder = Decoder()\n",
        "  data_pred = decoder.decode(encode_data, pca_val)\n",
        "  cluster = cluster_label_count(data_pred, data_y)\n",
        "\n",
        "  # initial evaluation class\n",
        "  eval = evaluation(cluster.to_numpy())  \n",
        "  # manual assign label to clusters\n",
        "  accu, pair_list = eval.manual_assign_label_cluster()\n",
        "  # purity\n",
        "  purity = eval.eval_purity()\n",
        "  # adjust rand index\n",
        "  adjusted_rand_index = eval.eval_ajusted_rand_index(data_pred, data_y)\n",
        "\n",
        "  return accu, purity, adjusted_rand_index"
      ],
      "metadata": {
        "id": "1KxgMSuhcu7a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "manutal_accu_list = []\n",
        "purity_list = []\n",
        "adj_list = []\n",
        "\n",
        "for i in range(5):\n",
        "  accu, purity, adjusted_rand_index = evaluation_results(model, train_uX_orig, train_uy_orig, 1+i*2)\n",
        "  manutal_accu_list.append(accu)\n",
        "  purity_list.append(purity)\n",
        "  adj_list.append(adjusted_rand_index)\n"
      ],
      "metadata": {
        "id": "sPZ7DvVgpyZi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the accuracy curve for the model training\n",
        "def show_accu(accu_list, purity_list, adj_list):\n",
        "  fig = plt.figure(figsize=(12,6))\n",
        "  plt.subplots_adjust(bottom=0.2,right=0.85,top=0.95)\n",
        "  ax = fig.add_subplot(1,1,1)\n",
        "\n",
        "  ax.clear()\n",
        "  ax.set_xlabel('pca value (10:100)')\n",
        "  ax.set_ylabel('accuracy value')\n",
        "  ax.set_title('Testing accuracy curve for model')\n",
        "  ax.plot(accu_list, label='manual labeled pair')\n",
        "  ax.plot(purity_list, label='purity')\n",
        "  ax.plot(adj_list, label='adjust rand index')\n",
        "  ax.legend(loc='upper right')\n",
        "  fig.canvas.draw()\n",
        "\n",
        "show_accu(manutal_accu_list,purity_list,adj_list)"
      ],
      "metadata": {
        "id": "7zS7TUqxv6YV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Summary: This plot does not show strong relationship between PCA values and prediction accuracy in our model."
      ],
      "metadata": {
        "id": "m3DaitbdzXT8"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CcohDGWOony"
      },
      "source": [
        "## **Part 7: Conclusion - Limitation & Future Improvement**\n",
        "The result produced by our 2-step method has shown around 7% improvement in the prediction accuracy for the unseen N class compare to the pure k-means clustering method. It also has shown around 10% improvement in the prediction accuracy for K+N (K seen, N unseen) class compare to the pure k-means clustering method. This is a moderate increase and there are room for improvement.\n",
        "\n",
        "One of the possible improvement is the design of the supervised network. Given our loss value 0.05, which is already very small, we achieve around 10% improvement in prediction accuracy. This implies that the loss function need to be improved for better indication of model accuracy and the network itself may require some redesign. Another limitations we have is the choice of the clustering method. Some other clustering method might be more appropriate to use. However, those methods might be complicated and so it is difficult to implement and we choose K-means instead. \n",
        "\n",
        "<!-- If the loss could be closer to 0, the network is likely to differentiate the K classes better given what it learned so far. The features we use to perform K-means might produce higher accuracy than the current one. We could achieve this by modifying our loss function or design a better network. -->\n",
        "\n",
        "\n",
        "\n",
        "There are also external limitations other than the design itself. One limitation of the work would be that the limited power of computation. If given a better computational resource, we would be able to train more complicated models and possibly obtain higher accuracy. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "US717RE5k0WK"
      },
      "source": [
        "### **Reference - Related Resources**\n",
        "\n",
        "Evaluation of clustering. (n.d.). Stanford University. Retrieved December 20, 2021, from https://nlp.stanford.edu/IR-book/html/htmledition/evaluation-of-clustering-1.html \n",
        "\n",
        "Doersch, C., Gupta, A., Efros, A. A. (2016, January 16). Unsupervised visual representation learning by context prediction. arXiv.org. Retrieved December 20, 2021, from https://arxiv.org/abs/1505.05192\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Adaptation to new classes using 2-step method.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}